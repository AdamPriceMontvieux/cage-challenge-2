{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCybORG\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAgents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mWrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RLlibWrapper\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "from CybORG import CybORG\n",
    "from CybORG.Agents import B_lineAgent, SleepAgent, GreenAgent\n",
    "from CybORG.Agents.SimpleAgents.BaseAgent import BaseAgent\n",
    "from CybORG.Agents.SimpleAgents.BlueReactAgent import BlueReactRemoveAgent\n",
    "from CybORG.Agents.SimpleAgents.Meander import RedMeanderAgent\n",
    "from CybORG.Agents.Wrappers.EnumActionWrapper import EnumActionWrapper\n",
    "from CybORG.Agents.Wrappers.FixedFlatWrapper import FixedFlatWrapper\n",
    "from CybORG.Agents.Wrappers.OpenAIGymWrapper import OpenAIGymWrapper\n",
    "from CybORG.Agents.Wrappers.ReduceActionSpaceWrapper import ReduceActionSpaceWrapper\n",
    "from CybORG.Agents.Wrappers import ChallengeWrapper\n",
    "import os\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.tune.registry import register_env\n",
    "from CybORG.Agents.Wrappers.rllib_wrapper import RLlibWrapper\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import ray\n",
    "from collections import deque\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPS = 50\n",
    "agent_name = 'Blue'\n",
    "\n",
    "def wrap(env):\n",
    "    return RLlibWrapper(agent_name=\"Blue\", env=env)\n",
    "\n",
    "\n",
    "def evaluate(steps):\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario1b.yaml'\n",
    "\n",
    "    #print(f'using CybORG v{cyborg_version}, {scenario}\\n')\n",
    "    for num_steps in steps:\n",
    "        for red_agent in [B_lineAgent, RedMeanderAgent, SleepAgent]:\n",
    "\n",
    "            cyborg = CybORG(path, 'sim', agents={'Red': red_agent})\n",
    "            wrapped_cyborg = wrap(cyborg)\n",
    "\n",
    "            observation = wrapped_cyborg.reset()\n",
    "            # observation = cyborg.reset().observation\n",
    "\n",
    "            action_space = wrapped_cyborg.get_action_space(agent_name)\n",
    "            # action_space = cyborg.get_action_space(agent_name)\n",
    "            total_reward = []\n",
    "            actions = []\n",
    "            for i in range(MAX_EPS):\n",
    "                r = []\n",
    "                a = []\n",
    "                # cyborg.env.env.tracker.render()\n",
    "                for j in range(num_steps):\n",
    "                    action = trainer.compute_single_action(observation)\n",
    "                    #action = agent.get_action(observation, action_space)\n",
    "                    observation, rew, done, info = wrapped_cyborg.step(action)\n",
    "                    # result = cyborg.step(agent_name, action)\n",
    "                    r.append(rew)\n",
    "                    # r.append(result.reward)\n",
    "                    a.append((str(cyborg.get_last_action('Blue')), str(cyborg.get_last_action('Red'))))\n",
    "                total_reward.append(sum(r))\n",
    "                actions.append(a)\n",
    "                # observation = cyborg.reset().observation\n",
    "                observation = wrapped_cyborg.reset()\n",
    "            print(f'Average reward for red agent {red_agent.__name__} and steps {num_steps} is: {mean(total_reward):.1f} with a standard deviation of {stdev(total_reward):.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.offline.json_writer import JsonWriter\n",
    "from ray.rllib.offline.dataset_writer import DatasetWriter\n",
    "from ray.rllib.offline.io_context import IOContext\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "def env_creator(env_config: dict):\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario1b.yaml'\n",
    "    agents = {\"Red\": B_lineAgent, \"Green\": GreenAgent}\n",
    "    cyborg = CybORG(scenario_file=path, environment='sim', agents=agents)\n",
    "    env = RLlibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)\n",
    "    return env\n",
    "\n",
    "def print_results(results_dict):\n",
    "    train_iter = results_dict[\"training_iteration\"]\n",
    "    r_mean = results_dict[\"episode_reward_mean\"]\n",
    "    r_max = results_dict[\"episode_reward_max\"]\n",
    "    r_min = results_dict[\"episode_reward_min\"]\n",
    "    print(f\"{train_iter:4d} \\tr_mean: {r_mean:.1f} \\tr_max: {r_max:.1f} \\tr_min: {r_min: .1f}\")\n",
    "    \n",
    "register_env(name=\"CybORG\", env_creator=env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deep Q-Networks (DQN, Rainbow, Parametric DQN)\n",
    "==============================================\n",
    "\n",
    "This file defines the distributed Trainer class for the Deep Q-Networks\n",
    "algorithm. See `dqn_[tf|torch]_policy.py` for the definition of the policies.\n",
    "\n",
    "Detailed documentation:\n",
    "https://docs.ray.io/en/master/rllib-algorithms.html#deep-q-networks-dqn-rainbow-parametric-dqn\n",
    "\"\"\"  # noqa: E501\n",
    "\n",
    "import logging\n",
    "from typing import List, Optional, Type\n",
    "\n",
    "from ray.rllib.agents.dqn.dqn_tf_policy import DQNTFPolicy\n",
    "from ray.rllib.agents.dqn.dqn_torch_policy import DQNTorchPolicy\n",
    "from ray.rllib.agents.dqn.simple_q import (\n",
    "    SimpleQTrainer,\n",
    "    DEFAULT_CONFIG as SIMPLEQ_DEFAULT_CONFIG,\n",
    ")\n",
    "from ray.rllib.agents.trainer import Trainer\n",
    "from ray.rllib.evaluation.worker_set import WorkerSet\n",
    "from ray.rllib.execution.concurrency_ops import Concurrently\n",
    "from ray.rllib.execution.metric_ops import StandardMetricsReporting\n",
    "from ray.rllib.execution.replay_ops import Replay, StoreToReplayBuffer\n",
    "from ray.rllib.execution.rollout_ops import ParallelRollouts\n",
    "from ray.rllib.execution.train_ops import (\n",
    "    TrainOneStep,\n",
    "    UpdateTargetNetwork,\n",
    "    MultiGPUTrainOneStep,\n",
    ")\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.deprecation import Deprecated\n",
    "from ray.rllib.utils.metrics.learner_info import LEARNER_STATS_KEY\n",
    "from ray.rllib.utils.typing import TrainerConfigDict\n",
    "from ray.util.iter import LocalIterator\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# fmt: off\n",
    "# __sphinx_doc_begin__\n",
    "DEFAULT_CONFIG = Trainer.merge_trainer_configs(\n",
    "    SIMPLEQ_DEFAULT_CONFIG,\n",
    "    {\n",
    "        # === Model ===\n",
    "        # Number of atoms for representing the distribution of return. When\n",
    "        # this is greater than 1, distributional Q-learning is used.\n",
    "        # the discrete supports are bounded by v_min and v_max\n",
    "        \"num_atoms\": 1,\n",
    "        \"v_min\": -10.0,\n",
    "        \"v_max\": 10.0,\n",
    "        # Whether to use noisy network\n",
    "        \"noisy\": False,\n",
    "        # control the initial value of noisy nets\n",
    "        \"sigma0\": 0.5,\n",
    "        # Whether to use dueling dqn\n",
    "        \"dueling\": True,\n",
    "        # Dense-layer setup for each the advantage branch and the value branch\n",
    "        # in a dueling architecture.\n",
    "        \"hiddens\": [256],\n",
    "        # Whether to use double dqn\n",
    "        \"double_q\": True,\n",
    "        # N-step Q learning\n",
    "        \"n_step\": 1,\n",
    "\n",
    "        # === Prioritized replay buffer ===\n",
    "        # If True prioritized replay buffer will be used.\n",
    "        \"prioritized_replay\": True,\n",
    "        # Alpha parameter for prioritized replay buffer.\n",
    "        \"prioritized_replay_alpha\": 0.6,\n",
    "        # Beta parameter for sampling from prioritized replay buffer.\n",
    "        \"prioritized_replay_beta\": 0.4,\n",
    "        # Final value of beta (by default, we use constant beta=0.4).\n",
    "        \"final_prioritized_replay_beta\": 0.4,\n",
    "        # Time steps over which the beta parameter is annealed.\n",
    "        \"prioritized_replay_beta_annealing_timesteps\": 20000,\n",
    "        # Epsilon to add to the TD errors when updating priorities.\n",
    "        \"prioritized_replay_eps\": 1e-6,\n",
    "\n",
    "        # Callback to run before learning on a multi-agent batch of\n",
    "        # experiences.\n",
    "        \"before_learn_on_batch\": None,\n",
    "\n",
    "        # The intensity with which to update the model (vs collecting samples\n",
    "        # from the env). If None, uses the \"natural\" value of:\n",
    "        # `train_batch_size` / (`rollout_fragment_length` x `num_workers` x\n",
    "        # `num_envs_per_worker`).\n",
    "        # If provided, will make sure that the ratio between ts inserted into\n",
    "        # and sampled from the buffer matches the given value.\n",
    "        # Example:\n",
    "        #   training_intensity=1000.0\n",
    "        #   train_batch_size=250 rollout_fragment_length=1\n",
    "        #   num_workers=1 (or 0) num_envs_per_worker=1\n",
    "        #   -> natural value = 250 / 1 = 250.0\n",
    "        #   -> will make sure that replay+train op will be executed 4x as\n",
    "        #      often as rollout+insert op (4 * 250 = 1000).\n",
    "        # See: rllib/agents/dqn/dqn.py::calculate_rr_weights for further\n",
    "        # details.\n",
    "        \"training_intensity\": None,\n",
    "\n",
    "        # === Parallelism ===\n",
    "        # Whether to compute priorities on workers.\n",
    "        \"worker_side_prioritization\": False,\n",
    "    },\n",
    "    _allow_unknown_configs=True,\n",
    ")\n",
    "# __sphinx_doc_end__\n",
    "# fmt: on\n",
    "\n",
    "\n",
    "def calculate_rr_weights(config: TrainerConfigDict) -> List[float]:\n",
    "    \"\"\"Calculate the round robin weights for the rollout and train steps\"\"\"\n",
    "    if not config[\"training_intensity\"]:\n",
    "        return [1, 1]\n",
    "\n",
    "    # Calculate the \"native ratio\" as:\n",
    "    # [train-batch-size] / [size of env-rolled-out sampled data]\n",
    "    # This is to set freshly rollout-collected data in relation to\n",
    "    # the data we pull from the replay buffer (which also contains old\n",
    "    # samples).\n",
    "    native_ratio = config[\"train_batch_size\"] / (\n",
    "        config[\"rollout_fragment_length\"]\n",
    "        * config[\"num_envs_per_worker\"]\n",
    "        * config[\"num_workers\"]\n",
    "    )\n",
    "\n",
    "    # Training intensity is specified in terms of\n",
    "    # (steps_replayed / steps_sampled), so adjust for the native ratio.\n",
    "    weights = [1, config[\"training_intensity\"] / native_ratio]\n",
    "    return weights\n",
    "\n",
    "\n",
    "class DQNTrainer_Offline(SimpleQTrainer):\n",
    "    @classmethod\n",
    "    @override(SimpleQTrainer)\n",
    "    def get_default_config(cls) -> TrainerConfigDict:\n",
    "        return DEFAULT_CONFIG\n",
    "\n",
    "    @override(SimpleQTrainer)\n",
    "    def validate_config(self, config: TrainerConfigDict) -> None:\n",
    "        # Call super's validation method.\n",
    "        super().validate_config(config)\n",
    "\n",
    "        # Update effective batch size to include n-step\n",
    "        adjusted_rollout_len = max(config[\"rollout_fragment_length\"], config[\"n_step\"])\n",
    "        config[\"rollout_fragment_length\"] = adjusted_rollout_len\n",
    "\n",
    "    @override(SimpleQTrainer)\n",
    "    def get_default_policy_class(\n",
    "        self, config: TrainerConfigDict\n",
    "    ) -> Optional[Type[Policy]]:\n",
    "        return DQNTFPolicyOffline\n",
    "\n",
    "    @staticmethod\n",
    "    @override(SimpleQTrainer)\n",
    "    def execution_plan(\n",
    "        workers: WorkerSet, config: TrainerConfigDict, **kwargs\n",
    "    ) -> LocalIterator[dict]:\n",
    "        assert (\n",
    "            \"local_replay_buffer\" in kwargs\n",
    "        ), \"DQN's execution plan requires a local replay buffer.\"\n",
    "\n",
    "        # Assign to Trainer, so we can store the MultiAgentReplayBuffer's\n",
    "        # data when we save checkpoints.\n",
    "        local_replay_buffer = kwargs[\"local_replay_buffer\"]\n",
    "\n",
    "        rollouts = ParallelRollouts(workers, mode=\"bulk_sync\")\n",
    "    \n",
    "        # We execute the following steps concurrently:\n",
    "        # (1) Generate rollouts and store them in our local replay buffer.\n",
    "        # Calling next() on store_op drives this.\n",
    "        store_op = rollouts.for_each(\n",
    "            StoreToReplayBuffer(local_buffer=local_replay_buffer)\n",
    "        )\n",
    "\n",
    "        def update_prio(item):\n",
    "            samples, info_dict = item\n",
    "            if config.get(\"prioritized_replay\"):\n",
    "                prio_dict = {}\n",
    "                for policy_id, info in info_dict.items():\n",
    "                    # TODO(sven): This is currently structured differently for\n",
    "                    #  torch/tf. Clean up these results/info dicts across\n",
    "                    #  policies (note: fixing this in torch_policy.py will\n",
    "                    #  break e.g. DDPPO!).\n",
    "                    td_error = info.get(\n",
    "                        \"td_error\", info[LEARNER_STATS_KEY].get(\"td_error\")\n",
    "                    )\n",
    "                    samples.policy_batches[policy_id].set_get_interceptor(None)\n",
    "                    batch_indices = samples.policy_batches[policy_id].get(\n",
    "                        \"batch_indexes\"\n",
    "                    )\n",
    "                    # In case the buffer stores sequences, TD-error could\n",
    "                    # already be calculated per sequence chunk.\n",
    "                    if len(batch_indices) != len(td_error):\n",
    "                        T = local_replay_buffer.replay_sequence_length\n",
    "                        assert (\n",
    "                            len(batch_indices) > len(td_error)\n",
    "                            and len(batch_indices) % T == 0\n",
    "                        )\n",
    "                        batch_indices = batch_indices.reshape([-1, T])[:, 0]\n",
    "                        assert len(batch_indices) == len(td_error)\n",
    "                    prio_dict[policy_id] = (batch_indices, td_error)\n",
    "                local_replay_buffer.update_priorities(prio_dict)\n",
    "            return info_dict\n",
    "\n",
    "        # (2) Read and train on experiences from the replay buffer. Every batch\n",
    "        # returned from the LocalReplay() iterator is passed to TrainOneStep to\n",
    "        # take a SGD step, and then we decide whether to update the target\n",
    "        # network.\n",
    "        post_fn = config.get(\"before_learn_on_batch\") or (lambda b, *a: b)\n",
    "\n",
    "        if config[\"simple_optimizer\"]:\n",
    "            train_step_op = TrainOneStep(workers)\n",
    "        else:\n",
    "            train_step_op = MultiGPUTrainOneStep(\n",
    "                workers=workers,\n",
    "                sgd_minibatch_size=config[\"train_batch_size\"],\n",
    "                num_sgd_iter=1,\n",
    "                num_gpus=config[\"num_gpus\"],\n",
    "                _fake_gpus=config[\"_fake_gpus\"],\n",
    "            )\n",
    "\n",
    "        replay_op = (\n",
    "            Replay(local_buffer=local_replay_buffer)\n",
    "            .for_each(lambda x: post_fn(x, workers, config))\n",
    "            .for_each(train_step_op)\n",
    "            .for_each(update_prio)\n",
    "            .for_each(\n",
    "                UpdateTargetNetwork(workers, config[\"target_network_update_freq\"])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Alternate deterministically between (1) and (2).\n",
    "        # Only return the output of (2) since training metrics are not\n",
    "        # available until (2) runs.\n",
    "        train_op = Concurrently(\n",
    "            [store_op, replay_op],\n",
    "            mode=\"round_robin\",\n",
    "            output_indexes=[1],\n",
    "            round_robin_weights=calculate_rr_weights(config),\n",
    "        )\n",
    "        return StandardMetricsReporting(train_op, workers, config)\n",
    "\n",
    "\n",
    "@Deprecated(\n",
    "    new=\"Sub-class directly from `DQNTrainer` and override its methods\", error=False\n",
    ")\n",
    "class GenericOffPolicyTrainer(DQNTrainer_Offline):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TensorFlow policy class used for DQN\"\"\"\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.rllib.agents.dqn.distributional_q_tf_model import DistributionalQTFModel\n",
    "from ray.rllib.agents.dqn.simple_q_tf_policy import TargetNetworkMixin\n",
    "from ray.rllib.evaluation.postprocessing import adjust_nstep\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.modelv2 import ModelV2\n",
    "from ray.rllib.models.tf.tf_action_dist import Categorical\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.policy.tf_policy import LearningRateSchedule\n",
    "from ray.rllib.policy.tf_policy_template import build_tf_policy\n",
    "from ray.rllib.utils.error import UnsupportedSpaceException\n",
    "from ray.rllib.utils.exploration import ParameterNoise\n",
    "from ray.rllib.utils.framework import try_import_tf\n",
    "from ray.rllib.utils.numpy import convert_to_numpy\n",
    "from ray.rllib.utils.tf_utils import (\n",
    "    huber_loss,\n",
    "    make_tf_callable,\n",
    "    minimize_and_clip,\n",
    "    reduce_mean_ignore_inf,\n",
    ")\n",
    "from ray.rllib.utils.typing import ModelGradients, TensorType, TrainerConfigDict\n",
    "\n",
    "tf1, tf, tfv = try_import_tf()\n",
    "\n",
    "Q_SCOPE = \"q_func\"\n",
    "Q_TARGET_SCOPE = \"target_q_func\"\n",
    "\n",
    "# Importance sampling weights for prioritized replay\n",
    "PRIO_WEIGHTS = \"weights\"\n",
    "\n",
    "\n",
    "class QLoss:\n",
    "    def __init__(\n",
    "        self,\n",
    "        q_t_selected: TensorType,\n",
    "        q_logits_t_selected: TensorType,\n",
    "        q_tp1_best: TensorType,\n",
    "        q_dist_tp1_best: TensorType,\n",
    "        importance_weights: TensorType,\n",
    "        rewards: TensorType,\n",
    "        done_mask: TensorType,\n",
    "        gamma: float = 0.99,\n",
    "        n_step: int = 1,\n",
    "        num_atoms: int = 1,\n",
    "        v_min: float = -10.0,\n",
    "        v_max: float = 0.0,\n",
    "    ):\n",
    "        \n",
    "\n",
    "        if num_atoms > 1:\n",
    "            # Distributional Q-learning which corresponds to an entropy loss\n",
    "\n",
    "            z = tf.range(num_atoms, dtype=tf.float32)\n",
    "            z = v_min + z * (v_max - v_min) / float(num_atoms - 1)\n",
    "\n",
    "            # (batch_size, 1) * (1, num_atoms) = (batch_size, num_atoms)\n",
    "            r_tau = tf.expand_dims(tf.cast(rewards, tf.float32), -1) + gamma ** n_step * tf.expand_dims(\n",
    "                1.0 - done_mask, -1\n",
    "            ) * tf.expand_dims(z, 0)\n",
    "            r_tau = tf.clip_by_value(r_tau, v_min, v_max)\n",
    "            b = (r_tau - v_min) / ((v_max - v_min) / float(num_atoms - 1))\n",
    "            lb = tf.floor(b)\n",
    "            ub = tf.math.ceil(b)\n",
    "            # indispensable judgement which is missed in most implementations\n",
    "            # when b happens to be an integer, lb == ub, so pr_j(s', a*) will\n",
    "            # be discarded because (ub-b) == (b-lb) == 0\n",
    "            floor_equal_ceil = tf.cast(tf.less(ub - lb, 0.5), tf.float32)\n",
    "\n",
    "            l_project = tf.one_hot(\n",
    "                tf.cast(lb, dtype=tf.int32), num_atoms\n",
    "            )  # (batch_size, num_atoms, num_atoms)\n",
    "            u_project = tf.one_hot(\n",
    "                tf.cast(ub, dtype=tf.int32), num_atoms\n",
    "            )  # (batch_size, num_atoms, num_atoms)\n",
    "            ml_delta = q_dist_tp1_best * (ub - b + floor_equal_ceil)\n",
    "            mu_delta = q_dist_tp1_best * (b - lb)\n",
    "            ml_delta = tf.reduce_sum(l_project * tf.expand_dims(ml_delta, -1), axis=1)\n",
    "            mu_delta = tf.reduce_sum(u_project * tf.expand_dims(mu_delta, -1), axis=1)\n",
    "            m = ml_delta + mu_delta\n",
    "\n",
    "            # Rainbow paper claims that using this cross entropy loss for\n",
    "            # priority is robust and insensitive to `prioritized_replay_alpha`\n",
    "            self.td_error = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=m, logits=q_logits_t_selected\n",
    "            )\n",
    "            self.loss = tf.reduce_mean(\n",
    "                self.td_error * tf.cast(importance_weights, tf.float32)\n",
    "            )\n",
    "            self.stats = {\n",
    "                # TODO: better Q stats for dist dqn\n",
    "                \"mean_td_error\": tf.reduce_mean(self.td_error),\n",
    "            }\n",
    "        else:\n",
    "            q_tp1_best_masked = (1.0 - done_mask) * q_tp1_best\n",
    "\n",
    "            # compute RHS of bellman equation\n",
    "            q_t_selected_target = tf.cast(rewards, tf.float32) + gamma ** n_step * q_tp1_best_masked\n",
    "\n",
    "            # compute the error (potentially clipped)\n",
    "            self.td_error = q_t_selected - tf.stop_gradient(q_t_selected_target)\n",
    "            self.loss = tf.reduce_mean(\n",
    "                tf.cast(importance_weights, tf.float32) * huber_loss(self.td_error)\n",
    "            )\n",
    "            self.stats = {\n",
    "                \"mean_q\": tf.reduce_mean(q_t_selected),\n",
    "                \"min_q\": tf.reduce_min(q_t_selected),\n",
    "                \"max_q\": tf.reduce_max(q_t_selected),\n",
    "                \"mean_td_error\": tf.reduce_mean(self.td_error),\n",
    "            }\n",
    "\n",
    "\n",
    "class ComputeTDErrorMixin:\n",
    "    \"\"\"Assign the `compute_td_error` method to the DQNTFPolicy\n",
    "\n",
    "    This allows us to prioritize on the worker side.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        @make_tf_callable(self.get_session(), dynamic_shape=True)\n",
    "        def compute_td_error(\n",
    "            obs_t, act_t, rew_t, obs_tp1, done_mask, importance_weights\n",
    "        ):\n",
    "            # Do forward pass on loss to update td error attribute\n",
    "            build_q_losses(\n",
    "                self,\n",
    "                self.model,\n",
    "                None,\n",
    "                {\n",
    "                    SampleBatch.CUR_OBS: tf.convert_to_tensor(obs_t),\n",
    "                    SampleBatch.ACTIONS: tf.convert_to_tensor(act_t),\n",
    "                    SampleBatch.REWARDS: tf.convert_to_tensor(rew_t),\n",
    "                    SampleBatch.NEXT_OBS: tf.convert_to_tensor(obs_tp1),\n",
    "                    SampleBatch.DONES: tf.convert_to_tensor(done_mask),\n",
    "                    PRIO_WEIGHTS: tf.convert_to_tensor(importance_weights),\n",
    "                },\n",
    "            )\n",
    "\n",
    "            return self.q_loss.td_error\n",
    "\n",
    "        self.compute_td_error = compute_td_error\n",
    "\n",
    "\n",
    "def build_q_model(\n",
    "    policy: Policy,\n",
    "    obs_space: gym.spaces.Space,\n",
    "    action_space: gym.spaces.Space,\n",
    "    config: TrainerConfigDict,\n",
    ") -> ModelV2:\n",
    "    \"\"\"Build q_model and target_model for DQN\n",
    "\n",
    "    Args:\n",
    "        policy (Policy): The Policy, which will use the model for optimization.\n",
    "        obs_space (gym.spaces.Space): The policy's observation space.\n",
    "        action_space (gym.spaces.Space): The policy's action space.\n",
    "        config (TrainerConfigDict):\n",
    "\n",
    "    Returns:\n",
    "        ModelV2: The Model for the Policy to use.\n",
    "            Note: The target q model will not be returned, just assigned to\n",
    "            `policy.target_model`.\n",
    "    \"\"\"\n",
    "    if not isinstance(action_space, gym.spaces.Discrete):\n",
    "        raise UnsupportedSpaceException(\n",
    "            \"Action space {} is not supported for DQN.\".format(action_space)\n",
    "        )\n",
    "\n",
    "    if config[\"hiddens\"]:\n",
    "        # try to infer the last layer size, otherwise fall back to 256\n",
    "        num_outputs = ([256] + list(config[\"model\"][\"fcnet_hiddens\"]))[-1]\n",
    "        config[\"model\"][\"no_final_linear\"] = True\n",
    "    else:\n",
    "        num_outputs = action_space.n\n",
    "\n",
    "    q_model = ModelCatalog.get_model_v2(\n",
    "        obs_space=obs_space,\n",
    "        action_space=action_space,\n",
    "        num_outputs=num_outputs,\n",
    "        model_config=config[\"model\"],\n",
    "        framework=\"tf\",\n",
    "        model_interface=DistributionalQTFModel,\n",
    "        name=Q_SCOPE,\n",
    "        num_atoms=config[\"num_atoms\"],\n",
    "        dueling=config[\"dueling\"],\n",
    "        q_hiddens=config[\"hiddens\"],\n",
    "        use_noisy=config[\"noisy\"],\n",
    "        v_min=config[\"v_min\"],\n",
    "        v_max=config[\"v_max\"],\n",
    "        sigma0=config[\"sigma0\"],\n",
    "        # TODO(sven): Move option to add LayerNorm after each Dense\n",
    "        #  generically into ModelCatalog.\n",
    "        add_layer_norm=isinstance(getattr(policy, \"exploration\", None), ParameterNoise)\n",
    "        or config[\"exploration_config\"][\"type\"] == \"ParameterNoise\",\n",
    "    )\n",
    "\n",
    "    policy.target_model = ModelCatalog.get_model_v2(\n",
    "        obs_space=obs_space,\n",
    "        action_space=action_space,\n",
    "        num_outputs=num_outputs,\n",
    "        model_config=config[\"model\"],\n",
    "        framework=\"tf\",\n",
    "        model_interface=DistributionalQTFModel,\n",
    "        name=Q_TARGET_SCOPE,\n",
    "        num_atoms=config[\"num_atoms\"],\n",
    "        dueling=config[\"dueling\"],\n",
    "        q_hiddens=config[\"hiddens\"],\n",
    "        use_noisy=config[\"noisy\"],\n",
    "        v_min=config[\"v_min\"],\n",
    "        v_max=config[\"v_max\"],\n",
    "        sigma0=config[\"sigma0\"],\n",
    "        # TODO(sven): Move option to add LayerNorm after each Dense\n",
    "        #  generically into ModelCatalog.\n",
    "        add_layer_norm=isinstance(getattr(policy, \"exploration\", None), ParameterNoise)\n",
    "        or config[\"exploration_config\"][\"type\"] == \"ParameterNoise\",\n",
    "    )\n",
    "\n",
    "    return q_model\n",
    "\n",
    "\n",
    "def get_distribution_inputs_and_class(\n",
    "    policy: Policy, model: ModelV2, input_dict: SampleBatch, *, explore=True, **kwargs\n",
    "):\n",
    "    q_vals = compute_q_values(\n",
    "        policy, model, input_dict, state_batches=None, explore=explore\n",
    "    )\n",
    "    q_vals = q_vals[0] if isinstance(q_vals, tuple) else q_vals\n",
    "\n",
    "    policy.q_values = q_vals\n",
    "\n",
    "    return policy.q_values, Categorical, []  # state-out\n",
    "\n",
    "\n",
    "def build_q_losses(policy: Policy, model, _, train_batch: SampleBatch) -> TensorType:\n",
    "    \"\"\"Constructs the loss for DQNTFPolicy.\n",
    "\n",
    "    Args:\n",
    "        policy (Policy): The Policy to calculate the loss for.\n",
    "        model (ModelV2): The Model to calculate the loss for.\n",
    "        train_batch (SampleBatch): The training data.\n",
    "\n",
    "    Returns:\n",
    "        TensorType: A single loss tensor.\n",
    "    \"\"\"\n",
    "    config = policy.config\n",
    "    # q network evaluation\n",
    "    q_t, q_logits_t, q_dist_t, _ = compute_q_values(\n",
    "        policy,\n",
    "        model,\n",
    "        SampleBatch({\"obs\": train_batch[SampleBatch.CUR_OBS]}),\n",
    "        state_batches=None,\n",
    "        explore=False,\n",
    "    )\n",
    "\n",
    "    # target q network evalution\n",
    "    q_tp1, q_logits_tp1, q_dist_tp1, _ = compute_q_values(\n",
    "        policy,\n",
    "        policy.target_model,\n",
    "        SampleBatch({\"obs\": train_batch[SampleBatch.NEXT_OBS]}),\n",
    "        state_batches=None,\n",
    "        explore=False,\n",
    "    )\n",
    "    if not hasattr(policy, \"target_q_func_vars\"):\n",
    "        policy.target_q_func_vars = policy.target_model.variables()\n",
    "\n",
    "    # q scores for actions which we know were selected in the given state.\n",
    "    one_hot_selection = tf.one_hot(\n",
    "        tf.cast(train_batch[SampleBatch.ACTIONS], tf.int32), policy.action_space.n\n",
    "    )\n",
    "    q_t_selected = tf.reduce_sum(q_t * one_hot_selection, 1)\n",
    "    q_logits_t_selected = tf.reduce_sum(\n",
    "        q_logits_t * tf.expand_dims(one_hot_selection, -1), 1\n",
    "    )\n",
    "\n",
    "    # compute estimate of best possible value starting from state at t + 1\n",
    "    if config[\"double_q\"]:\n",
    "        (\n",
    "            q_tp1_using_online_net,\n",
    "            q_logits_tp1_using_online_net,\n",
    "            q_dist_tp1_using_online_net,\n",
    "            _,\n",
    "        ) = compute_q_values(\n",
    "            policy,\n",
    "            model,\n",
    "            SampleBatch({\"obs\": train_batch[SampleBatch.NEXT_OBS]}),\n",
    "            state_batches=None,\n",
    "            explore=False,\n",
    "        )\n",
    "        q_tp1_best_using_online_net = tf.argmax(q_tp1_using_online_net, 1)\n",
    "        q_tp1_best_one_hot_selection = tf.one_hot(\n",
    "            q_tp1_best_using_online_net, policy.action_space.n\n",
    "        )\n",
    "        q_tp1_best = tf.reduce_sum(q_tp1 * q_tp1_best_one_hot_selection, 1)\n",
    "        q_dist_tp1_best = tf.reduce_sum(\n",
    "            q_dist_tp1 * tf.expand_dims(q_tp1_best_one_hot_selection, -1), 1\n",
    "        )\n",
    "    else:\n",
    "        q_tp1_best_one_hot_selection = tf.one_hot(\n",
    "            tf.argmax(q_tp1, 1), policy.action_space.n\n",
    "        )\n",
    "        q_tp1_best = tf.reduce_sum(q_tp1 * q_tp1_best_one_hot_selection, 1)\n",
    "        q_dist_tp1_best = tf.reduce_sum(\n",
    "            q_dist_tp1 * tf.expand_dims(q_tp1_best_one_hot_selection, -1), 1\n",
    "        )\n",
    "\n",
    "    policy.q_loss = QLoss(\n",
    "        q_t_selected,\n",
    "        q_logits_t_selected,\n",
    "        q_tp1_best,\n",
    "        q_dist_tp1_best,\n",
    "        train_batch[PRIO_WEIGHTS],\n",
    "        train_batch[SampleBatch.REWARDS],\n",
    "        tf.cast(train_batch[SampleBatch.DONES], tf.float32),\n",
    "        config[\"gamma\"],\n",
    "        config[\"n_step\"],\n",
    "        config[\"num_atoms\"],\n",
    "        config[\"v_min\"],\n",
    "        config[\"v_max\"],\n",
    "    )\n",
    "\n",
    "    return policy.q_loss.loss\n",
    "\n",
    "\n",
    "def adam_optimizer(\n",
    "    policy: Policy, config: TrainerConfigDict\n",
    ") -> \"tf.keras.optimizers.Optimizer\":\n",
    "    if policy.config[\"framework\"] in [\"tf2\", \"tfe\"]:\n",
    "        return tf.keras.optimizers.Adam(\n",
    "            learning_rate=policy.cur_lr, epsilon=config[\"adam_epsilon\"]\n",
    "        )\n",
    "    else:\n",
    "        return tf1.train.AdamOptimizer(\n",
    "            learning_rate=policy.cur_lr, epsilon=config[\"adam_epsilon\"]\n",
    "        )\n",
    "\n",
    "\n",
    "def clip_gradients(\n",
    "    policy: Policy, optimizer: \"tf.keras.optimizers.Optimizer\", loss: TensorType\n",
    ") -> ModelGradients:\n",
    "    if not hasattr(policy, \"q_func_vars\"):\n",
    "        policy.q_func_vars = policy.model.variables()\n",
    "\n",
    "    return minimize_and_clip(\n",
    "        optimizer,\n",
    "        loss,\n",
    "        var_list=policy.q_func_vars,\n",
    "        clip_val=policy.config[\"grad_clip\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def build_q_stats(policy: Policy, batch) -> Dict[str, TensorType]:\n",
    "    return dict(\n",
    "        {\n",
    "            \"cur_lr\": tf.cast(policy.cur_lr, tf.float64),\n",
    "        },\n",
    "        **policy.q_loss.stats\n",
    "    )\n",
    "\n",
    "\n",
    "def setup_mid_mixins(policy: Policy, obs_space, action_space, config) -> None:\n",
    "    LearningRateSchedule.__init__(policy, config[\"lr\"], config[\"lr_schedule\"])\n",
    "    ComputeTDErrorMixin.__init__(policy)\n",
    "\n",
    "\n",
    "def setup_late_mixins(\n",
    "    policy: Policy,\n",
    "    obs_space: gym.spaces.Space,\n",
    "    action_space: gym.spaces.Space,\n",
    "    config: TrainerConfigDict,\n",
    ") -> None:\n",
    "    TargetNetworkMixin.__init__(policy, obs_space, action_space, config)\n",
    "\n",
    "\n",
    "def compute_q_values(\n",
    "    policy: Policy,\n",
    "    model: ModelV2,\n",
    "    input_batch: SampleBatch,\n",
    "    state_batches=None,\n",
    "    seq_lens=None,\n",
    "    explore=None,\n",
    "    is_training: bool = False,\n",
    "):\n",
    "\n",
    "    config = policy.config\n",
    "\n",
    "    model_out, state = model(input_batch, state_batches or [], seq_lens)\n",
    "\n",
    "    if config[\"num_atoms\"] > 1:\n",
    "        (\n",
    "            action_scores,\n",
    "            z,\n",
    "            support_logits_per_action,\n",
    "            logits,\n",
    "            dist,\n",
    "        ) = model.get_q_value_distributions(model_out)\n",
    "    else:\n",
    "        (action_scores, logits, dist) = model.get_q_value_distributions(model_out)\n",
    "\n",
    "    if config[\"dueling\"]:\n",
    "        state_score = model.get_state_value(model_out)\n",
    "        if config[\"num_atoms\"] > 1:\n",
    "            support_logits_per_action_mean = tf.reduce_mean(\n",
    "                support_logits_per_action, 1\n",
    "            )\n",
    "            support_logits_per_action_centered = (\n",
    "                support_logits_per_action\n",
    "                - tf.expand_dims(support_logits_per_action_mean, 1)\n",
    "            )\n",
    "            support_logits_per_action = (\n",
    "                tf.expand_dims(state_score, 1) + support_logits_per_action_centered\n",
    "            )\n",
    "            support_prob_per_action = tf.nn.softmax(logits=support_logits_per_action)\n",
    "            value = tf.reduce_sum(input_tensor=z * support_prob_per_action, axis=-1)\n",
    "            logits = support_logits_per_action\n",
    "            dist = support_prob_per_action\n",
    "        else:\n",
    "            action_scores_mean = reduce_mean_ignore_inf(action_scores, 1)\n",
    "            action_scores_centered = action_scores - tf.expand_dims(\n",
    "                action_scores_mean, 1\n",
    "            )\n",
    "            value = state_score + action_scores_centered\n",
    "    else:\n",
    "        value = action_scores\n",
    "\n",
    "    return value, logits, dist, state\n",
    "\n",
    "\n",
    "def postprocess_nstep_and_prio(\n",
    "    policy: Policy, batch: SampleBatch, other_agent=None, episode=None\n",
    ") -> SampleBatch:\n",
    "    # N-step Q adjustments.\n",
    "    if policy.config[\"n_step\"] > 1:\n",
    "        adjust_nstep(policy.config[\"n_step\"], policy.config[\"gamma\"], batch)\n",
    "\n",
    "    # Create dummy prio-weights (1.0) in case we don't have any in\n",
    "    # the batch.\n",
    "    if PRIO_WEIGHTS not in batch:\n",
    "        batch[PRIO_WEIGHTS] = np.ones_like(batch[SampleBatch.REWARDS])\n",
    "\n",
    "    # Prioritize on the worker side.\n",
    "    if batch.count > 0 and policy.config[\"worker_side_prioritization\"]:\n",
    "        td_errors = policy.compute_td_error(\n",
    "            batch[SampleBatch.OBS],\n",
    "            batch[SampleBatch.ACTIONS],\n",
    "            batch[SampleBatch.REWARDS],\n",
    "            batch[SampleBatch.NEXT_OBS],\n",
    "            batch[SampleBatch.DONES],\n",
    "            batch[PRIO_WEIGHTS],\n",
    "        )\n",
    "        new_priorities = (\n",
    "            np.abs(convert_to_numpy(td_errors))\n",
    "            + policy.config[\"prioritized_replay_eps\"]\n",
    "        )\n",
    "        batch[PRIO_WEIGHTS] = new_priorities\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "DQNTFPolicyOffline = build_tf_policy(\n",
    "    name=\"DQNTFPolicyOffline\",\n",
    "    get_default_config=lambda: ray.rllib.agents.dqn.dqn.DEFAULT_CONFIG,\n",
    "    make_model=build_q_model,\n",
    "    action_distribution_fn=get_distribution_inputs_and_class,\n",
    "    loss_fn=build_q_losses,\n",
    "    stats_fn=build_q_stats,\n",
    "    postprocess_fn=postprocess_nstep_and_prio,\n",
    "    optimizer_fn=adam_optimizer,\n",
    "    compute_gradients_fn=clip_gradients,\n",
    "    extra_action_out_fn=lambda policy: {\"q_values\": policy.q_values},\n",
    "    extra_learn_fetches_fn=lambda policy: {\"td_error\": policy.q_loss.td_error},\n",
    "    before_loss_init=setup_mid_mixins,\n",
    "    after_init=setup_late_mixins,\n",
    "    mixins=[\n",
    "        TargetNetworkMixin,\n",
    "        ComputeTDErrorMixin,\n",
    "        LearningRateSchedule,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 0,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 4,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'gamma': 0.99,\n",
       " 'lr': 0.0005,\n",
       " 'train_batch_size': 32,\n",
       " 'model': {'_use_default_native_models': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'post_fcnet_hiddens': [],\n",
       "  'post_fcnet_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'attention_use_n_prev_actions': 0,\n",
       "  'attention_use_n_prev_rewards': 0,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1},\n",
       " 'optimizer': {},\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env': None,\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_config': {},\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'record_env': False,\n",
       " 'clip_rewards': None,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'recreate_failed_workers': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'EpsilonGreedy',\n",
       "  'initial_epsilon': 1.0,\n",
       "  'final_epsilon': 0.02,\n",
       "  'epsilon_timesteps': 10000},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_duration': 10,\n",
       " 'evaluation_duration_unit': 'episodes',\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {'explore': False},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'always_attach_evaluation_results': False,\n",
       " 'keep_per_episode_custom_metrics': False,\n",
       " 'sample_async': False,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'metrics_episode_collection_timeout_s': 180,\n",
       " 'metrics_num_episodes_for_smoothing': 100,\n",
       " 'min_time_s_per_reporting': 1,\n",
       " 'min_train_timesteps_per_reporting': None,\n",
       " 'min_sample_timesteps_per_reporting': None,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 0,\n",
       " '_fake_gpus': False,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'placement_strategy': 'PACK',\n",
       " 'input': 'sampler',\n",
       " 'input_config': {},\n",
       " 'actions_in_input_normalized': False,\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_config': {},\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_map_cache': None,\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'logger_config': None,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " '_disable_action_flattening': False,\n",
       " '_disable_execution_plan_api': True,\n",
       " 'disable_env_checking': False,\n",
       " 'simple_optimizer': -1,\n",
       " 'monitor': -1,\n",
       " 'evaluation_num_episodes': -1,\n",
       " 'metrics_smoothing_episodes': -1,\n",
       " 'timesteps_per_iteration': 1000,\n",
       " 'min_iter_time_s': -1,\n",
       " 'collect_metrics_timeout': -1,\n",
       " 'target_network_update_freq': 500,\n",
       " 'buffer_size': -1,\n",
       " 'prioritized_replay': -1,\n",
       " 'learning_starts': -1,\n",
       " 'replay_batch_size': -1,\n",
       " 'replay_sequence_length': -1,\n",
       " 'prioritized_replay_alpha': -1,\n",
       " 'prioritized_replay_beta': -1,\n",
       " 'prioritized_replay_eps': -1,\n",
       " 'replay_buffer_config': {'_enable_replay_buffer_api': True,\n",
       "  'type': 'MultiAgentPrioritizedReplayBuffer',\n",
       "  'capacity': 50000,\n",
       "  'prioritized_replay_alpha': 0.6,\n",
       "  'prioritized_replay_beta': 0.4,\n",
       "  'prioritized_replay_eps': 1e-06,\n",
       "  'replay_sequence_length': 1},\n",
       " 'store_buffer_in_checkpoints': False,\n",
       " 'lr_schedule': None,\n",
       " 'adam_epsilon': 1e-08,\n",
       " 'grad_clip': 40,\n",
       " 'num_atoms': 1,\n",
       " 'v_min': -10.0,\n",
       " 'v_max': 10.0,\n",
       " 'noisy': False,\n",
       " 'sigma0': 0.5,\n",
       " 'dueling': True,\n",
       " 'hiddens': [256],\n",
       " 'double_q': True,\n",
       " 'n_step': 1,\n",
       " 'before_learn_on_batch': None,\n",
       " 'training_intensity': None,\n",
       " 'worker_side_prioritization': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.agents.dqn import dqn\n",
    "dqn.DEFAULT_CONFIG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=36851)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36851)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36853)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36853)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36851)\u001b[0m 2022-06-27 17:36:49,468\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36858)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36858)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36856)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36856)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36860)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36860)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36853)\u001b[0m 2022-06-27 17:36:50,162\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36858)\u001b[0m 2022-06-27 17:36:50,159\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36863)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36863)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36910)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36910)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36882)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36882)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36856)\u001b[0m 2022-06-27 17:36:50,577\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36938)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36938)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36977)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36977)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36860)\u001b[0m 2022-06-27 17:36:50,801\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36863)\u001b[0m 2022-06-27 17:36:50,883\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36882)\u001b[0m 2022-06-27 17:36:51,070\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36910)\u001b[0m 2022-06-27 17:36:51,040\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36938)\u001b[0m 2022-06-27 17:36:51,317\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37008)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37008)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=36977)\u001b[0m 2022-06-27 17:36:51,475\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37090)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37090)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37064)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37064)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37130)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37130)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37008)\u001b[0m 2022-06-27 17:36:52,019\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37144)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37144)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37090)\u001b[0m 2022-06-27 17:36:52,328\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37064)\u001b[0m 2022-06-27 17:36:52,329\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37180)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37180)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37130)\u001b[0m 2022-06-27 17:36:52,604\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37201)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37201)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37229)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37229)\u001b[0m   \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=37144)\u001b[0m 2022-06-27 17:36:52,836\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37180)\u001b[0m 2022-06-27 17:36:52,969\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37272)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37272)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37286)\u001b[0m /usr/local/lib/python3.8/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37286)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37201)\u001b[0m 2022-06-27 17:36:53,462\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37229)\u001b[0m 2022-06-27 17:36:53,490\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37272)\u001b[0m 2022-06-27 17:36:53,862\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37286)\u001b[0m 2022-06-27 17:36:54,078\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "2022-06-27 17:36:57,202\tINFO trainable.py:159 -- Trainable.setup took 16.111 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-06-27 17:36:57,206\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "2022-06-27 17:36:57,979\tWARNING multi_agent_prioritized_replay_buffer.py:186 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 \tr_mean: nan \tr_max: nan \tr_min:  nan\n",
      "   2 \tr_mean: -203.4 \tr_max: -154.5 \tr_min: -273.3\n",
      "   3 \tr_mean: -203.4 \tr_max: -154.5 \tr_min: -273.3\n",
      "   4 \tr_mean: -200.3 \tr_max: -129.6 \tr_min: -273.3\n",
      "   5 \tr_mean: -200.3 \tr_max: -129.6 \tr_min: -273.3\n",
      "   6 \tr_mean: -204.9 \tr_max: -129.6 \tr_min: -283.8\n",
      "   7 \tr_mean: -204.9 \tr_max: -129.6 \tr_min: -283.8\n",
      "   8 \tr_mean: -204.9 \tr_max: -127.3 \tr_min: -283.8\n",
      "   9 \tr_mean: -204.0 \tr_max: -127.1 \tr_min: -283.8\n",
      "  10 \tr_mean: -204.0 \tr_max: -127.1 \tr_min: -283.8\n",
      "  11 \tr_mean: -205.8 \tr_max: -127.1 \tr_min: -283.8\n",
      "  12 \tr_mean: -205.8 \tr_max: -127.1 \tr_min: -283.8\n",
      "  13 \tr_mean: -210.8 \tr_max: -125.8 \tr_min: -283.8\n",
      "  14 \tr_mean: -210.8 \tr_max: -125.8 \tr_min: -283.8\n",
      "  15 \tr_mean: -210.2 \tr_max: -125.8 \tr_min: -283.8\n",
      "  16 \tr_mean: -210.2 \tr_max: -125.8 \tr_min: -283.8\n",
      "  17 \tr_mean: -211.9 \tr_max: -110.7 \tr_min: -283.8\n",
      "  18 \tr_mean: -210.6 \tr_max: -110.7 \tr_min: -283.8\n",
      "  19 \tr_mean: -210.6 \tr_max: -110.7 \tr_min: -283.8\n",
      "  20 \tr_mean: -210.5 \tr_max: -110.7 \tr_min: -288.8\n",
      "  21 \tr_mean: -210.5 \tr_max: -110.7 \tr_min: -288.8\n",
      "  22 \tr_mean: -209.7 \tr_max: -110.7 \tr_min: -288.8\n",
      "  23 \tr_mean: -209.7 \tr_max: -110.7 \tr_min: -288.8\n",
      "  24 \tr_mean: -211.4 \tr_max: -110.7 \tr_min: -288.8\n",
      "  25 \tr_mean: -213.7 \tr_max: -126.8 \tr_min: -307.8\n",
      "  26 \tr_mean: -213.7 \tr_max: -126.8 \tr_min: -307.8\n",
      "  27 \tr_mean: -218.3 \tr_max: -126.8 \tr_min: -307.8\n",
      "  28 \tr_mean: -218.3 \tr_max: -126.8 \tr_min: -307.8\n",
      "  29 \tr_mean: -217.9 \tr_max: -126.8 \tr_min: -307.8\n",
      "  30 \tr_mean: -217.9 \tr_max: -126.8 \tr_min: -307.8\n",
      "  31 \tr_mean: -214.4 \tr_max: -158.0 \tr_min: -307.8\n",
      "  32 \tr_mean: -214.4 \tr_max: -158.0 \tr_min: -307.8\n",
      "  33 \tr_mean: -206.0 \tr_max: -109.3 \tr_min: -307.8\n",
      "  34 \tr_mean: -199.4 \tr_max: -109.3 \tr_min: -282.8\n",
      "  35 \tr_mean: -199.4 \tr_max: -109.3 \tr_min: -282.8\n",
      "  36 \tr_mean: -192.6 \tr_max: -109.3 \tr_min: -282.8\n",
      "  37 \tr_mean: -192.6 \tr_max: -109.3 \tr_min: -282.8\n",
      "  38 \tr_mean: -181.8 \tr_max: -109.3 \tr_min: -282.8\n",
      "  39 \tr_mean: -181.8 \tr_max: -109.3 \tr_min: -282.8\n",
      "  40 \tr_mean: -182.0 \tr_max: -109.3 \tr_min: -261.6\n",
      "  41 \tr_mean: -182.0 \tr_max: -109.3 \tr_min: -261.6\n",
      "  42 \tr_mean: -189.3 \tr_max: -117.6 \tr_min: -261.6\n",
      "  43 \tr_mean: -196.3 \tr_max: -117.6 \tr_min: -270.7\n",
      "  44 \tr_mean: -196.3 \tr_max: -117.6 \tr_min: -270.7\n",
      "  45 \tr_mean: -204.5 \tr_max: -117.6 \tr_min: -286.8\n",
      "  46 \tr_mean: -204.5 \tr_max: -117.6 \tr_min: -286.8\n",
      "  47 \tr_mean: -220.8 \tr_max: -137.1 \tr_min: -286.8\n",
      "  48 \tr_mean: -220.8 \tr_max: -137.1 \tr_min: -286.8\n",
      "  49 \tr_mean: -220.8 \tr_max: -147.3 \tr_min: -286.8\n",
      "  50 \tr_mean: -210.4 \tr_max: -74.8 \tr_min: -286.8\n",
      "  51 \tr_mean: -210.4 \tr_max: -74.8 \tr_min: -286.8\n",
      "  52 \tr_mean: -196.1 \tr_max: -72.8 \tr_min: -286.8\n",
      "  53 \tr_mean: -196.1 \tr_max: -72.8 \tr_min: -286.8\n",
      "  54 \tr_mean: -182.0 \tr_max: -72.8 \tr_min: -275.0\n",
      "  55 \tr_mean: -182.0 \tr_max: -72.8 \tr_min: -275.0\n",
      "  56 \tr_mean: -164.8 \tr_max: -72.8 \tr_min: -255.4\n",
      "  57 \tr_mean: -164.8 \tr_max: -72.8 \tr_min: -255.4\n",
      "  58 \tr_mean: -155.5 \tr_max: -72.8 \tr_min: -249.7\n",
      "  59 \tr_mean: -152.7 \tr_max: -72.8 \tr_min: -249.7\n",
      "  60 \tr_mean: -152.7 \tr_max: -72.8 \tr_min: -249.7\n",
      "  61 \tr_mean: -149.2 \tr_max: -67.8 \tr_min: -249.7\n",
      "  62 \tr_mean: -149.2 \tr_max: -67.8 \tr_min: -249.7\n",
      "  63 \tr_mean: -146.3 \tr_max: -31.7 \tr_min: -248.9\n",
      "  64 \tr_mean: -146.3 \tr_max: -31.7 \tr_min: -248.9\n",
      "  65 \tr_mean: -142.0 \tr_max: -31.7 \tr_min: -242.8\n",
      "  66 \tr_mean: -142.0 \tr_max: -31.7 \tr_min: -242.8\n",
      "  67 \tr_mean: -135.1 \tr_max: -31.7 \tr_min: -241.8\n",
      "  68 \tr_mean: -134.3 \tr_max: -31.7 \tr_min: -227.8\n",
      "  69 \tr_mean: -134.3 \tr_max: -31.7 \tr_min: -227.8\n",
      "  70 \tr_mean: -136.2 \tr_max: -31.7 \tr_min: -227.8\n",
      "  71 \tr_mean: -136.2 \tr_max: -31.7 \tr_min: -227.8\n",
      "  72 \tr_mean: -128.6 \tr_max: -42.5 \tr_min: -224.8\n",
      "  73 \tr_mean: -128.6 \tr_max: -42.5 \tr_min: -224.8\n",
      "  74 \tr_mean: -123.9 \tr_max: -42.5 \tr_min: -190.8\n",
      "  75 \tr_mean: -121.6 \tr_max: -31.8 \tr_min: -205.7\n",
      "  76 \tr_mean: -121.6 \tr_max: -31.8 \tr_min: -205.7\n",
      "  77 \tr_mean: -117.0 \tr_max: -31.8 \tr_min: -205.7\n",
      "  78 \tr_mean: -117.0 \tr_max: -31.8 \tr_min: -205.7\n",
      "  79 \tr_mean: -110.0 \tr_max: -31.8 \tr_min: -205.7\n",
      "  80 \tr_mean: -110.0 \tr_max: -31.8 \tr_min: -205.7\n",
      "  81 \tr_mean: -109.3 \tr_max: -31.8 \tr_min: -205.7\n",
      "  82 \tr_mean: -109.3 \tr_max: -31.8 \tr_min: -205.7\n",
      "  83 \tr_mean: -114.9 \tr_max: -31.8 \tr_min: -264.7\n",
      "  84 \tr_mean: -111.4 \tr_max: -43.7 \tr_min: -264.7\n",
      "  85 \tr_mean: -111.4 \tr_max: -43.7 \tr_min: -264.7\n",
      "  86 \tr_mean: -105.8 \tr_max: -55.2 \tr_min: -264.7\n",
      "  87 \tr_mean: -105.8 \tr_max: -55.2 \tr_min: -264.7\n",
      "  88 \tr_mean: -104.5 \tr_max: -55.2 \tr_min: -264.7\n",
      "  89 \tr_mean: -104.5 \tr_max: -55.2 \tr_min: -264.7\n",
      "  90 \tr_mean: -108.2 \tr_max: -56.3 \tr_min: -264.7\n",
      "  91 \tr_mean: -108.2 \tr_max: -56.3 \tr_min: -264.7\n",
      "  92 \tr_mean: -101.7 \tr_max: -56.3 \tr_min: -185.8\n",
      "  93 \tr_mean: -109.2 \tr_max: -56.3 \tr_min: -217.0\n",
      "  94 \tr_mean: -109.2 \tr_max: -56.3 \tr_min: -217.0\n",
      "  95 \tr_mean: -119.8 \tr_max: -57.9 \tr_min: -248.2\n",
      "  96 \tr_mean: -119.8 \tr_max: -57.9 \tr_min: -248.2\n",
      "  97 \tr_mean: -127.1 \tr_max: -57.9 \tr_min: -263.8\n",
      "  98 \tr_mean: -127.1 \tr_max: -57.9 \tr_min: -263.8\n",
      "  99 \tr_mean: -123.9 \tr_max: -49.3 \tr_min: -263.8\n",
      " 100 \tr_mean: -122.0 \tr_max: -49.3 \tr_min: -263.8\n",
      " 101 \tr_mean: -122.0 \tr_max: -49.3 \tr_min: -263.8\n",
      " 102 \tr_mean: -113.3 \tr_max: -49.3 \tr_min: -263.8\n",
      " 103 \tr_mean: -113.3 \tr_max: -49.3 \tr_min: -263.8\n",
      " 104 \tr_mean: -107.0 \tr_max: -49.3 \tr_min: -263.8\n",
      " 105 \tr_mean: -107.0 \tr_max: -49.3 \tr_min: -263.8\n",
      " 106 \tr_mean: -100.6 \tr_max: -49.3 \tr_min: -243.3\n",
      " 107 \tr_mean: -100.6 \tr_max: -49.3 \tr_min: -243.3\n",
      " 108 \tr_mean: -102.2 \tr_max: -62.4 \tr_min: -190.8\n",
      " 109 \tr_mean: -108.1 \tr_max: -71.8 \tr_min: -193.8\n",
      " 110 \tr_mean: -108.1 \tr_max: -71.8 \tr_min: -193.8\n",
      " 111 \tr_mean: -113.1 \tr_max: -80.8 \tr_min: -193.8\n",
      " 112 \tr_mean: -113.1 \tr_max: -80.8 \tr_min: -193.8\n",
      " 113 \tr_mean: -113.4 \tr_max: -80.8 \tr_min: -193.8\n",
      " 114 \tr_mean: -113.4 \tr_max: -80.8 \tr_min: -193.8\n",
      " 115 \tr_mean: -109.3 \tr_max: -77.8 \tr_min: -193.8\n",
      " 116 \tr_mean: -109.3 \tr_max: -77.8 \tr_min: -193.8\n",
      " 117 \tr_mean: -103.1 \tr_max: -70.6 \tr_min: -193.8\n",
      " 118 \tr_mean: -93.7 \tr_max: -66.5 \tr_min: -173.8\n",
      " 119 \tr_mean: -93.7 \tr_max: -66.5 \tr_min: -173.8\n",
      " 120 \tr_mean: -86.9 \tr_max: -66.5 \tr_min: -173.6\n",
      " 121 \tr_mean: -86.9 \tr_max: -66.5 \tr_min: -173.6\n",
      " 122 \tr_mean: -82.9 \tr_max: -66.5 \tr_min: -141.2\n",
      " 123 \tr_mean: -82.9 \tr_max: -66.5 \tr_min: -141.2\n",
      " 124 \tr_mean: -84.5 \tr_max: -66.5 \tr_min: -116.0\n",
      " 125 \tr_mean: -90.0 \tr_max: -66.5 \tr_min: -180.3\n",
      " 126 \tr_mean: -90.0 \tr_max: -66.5 \tr_min: -180.3\n",
      " 127 \tr_mean: -94.1 \tr_max: -68.7 \tr_min: -180.3\n",
      " 128 \tr_mean: -94.1 \tr_max: -68.7 \tr_min: -180.3\n",
      " 129 \tr_mean: -95.9 \tr_max: -79.3 \tr_min: -180.3\n",
      " 130 \tr_mean: -95.9 \tr_max: -79.3 \tr_min: -180.3\n",
      " 131 \tr_mean: -96.4 \tr_max: -79.3 \tr_min: -180.3\n",
      " 132 \tr_mean: -96.4 \tr_max: -79.3 \tr_min: -180.3\n",
      " 133 \tr_mean: -97.3 \tr_max: -79.3 \tr_min: -180.3\n",
      " 134 \tr_mean: -94.3 \tr_max: -79.3 \tr_min: -146.2\n",
      " 135 \tr_mean: -94.3 \tr_max: -79.3 \tr_min: -146.2\n",
      " 136 \tr_mean: -97.0 \tr_max: -79.3 \tr_min: -162.1\n",
      " 137 \tr_mean: -97.0 \tr_max: -79.3 \tr_min: -162.1\n",
      " 138 \tr_mean: -100.3 \tr_max: -83.6 \tr_min: -162.1\n",
      " 139 \tr_mean: -100.3 \tr_max: -83.6 \tr_min: -162.1\n",
      " 140 \tr_mean: -103.7 \tr_max: -83.6 \tr_min: -198.9\n",
      " 141 \tr_mean: -103.7 \tr_max: -83.6 \tr_min: -198.9\n",
      " 142 \tr_mean: -105.9 \tr_max: -83.6 \tr_min: -205.8\n",
      " 143 \tr_mean: -110.4 \tr_max: -97.2 \tr_min: -205.8\n",
      " 144 \tr_mean: -110.4 \tr_max: -97.2 \tr_min: -205.8\n",
      " 145 \tr_mean: -115.0 \tr_max: -98.9 \tr_min: -335.6\n",
      " 146 \tr_mean: -115.0 \tr_max: -98.9 \tr_min: -335.6\n",
      " 147 \tr_mean: -117.5 \tr_max: -98.8 \tr_min: -335.6\n",
      " 148 \tr_mean: -117.5 \tr_max: -98.8 \tr_min: -335.6\n",
      " 149 \tr_mean: -114.5 \tr_max: -92.1 \tr_min: -335.6\n",
      " 150 \tr_mean: -108.7 \tr_max: -70.7 \tr_min: -335.6\n",
      " 151 \tr_mean: -108.7 \tr_max: -70.7 \tr_min: -335.6\n",
      " 152 \tr_mean: -102.2 \tr_max: -67.5 \tr_min: -335.6\n",
      " 153 \tr_mean: -102.2 \tr_max: -67.5 \tr_min: -335.6\n",
      " 154 \tr_mean: -95.1 \tr_max: -67.5 \tr_min: -232.2\n",
      " 155 \tr_mean: -95.1 \tr_max: -67.5 \tr_min: -232.2\n",
      " 156 \tr_mean: -89.7 \tr_max: -67.5 \tr_min: -232.2\n",
      " 157 \tr_mean: -89.7 \tr_max: -67.5 \tr_min: -232.2\n",
      " 158 \tr_mean: -85.0 \tr_max: -67.5 \tr_min: -232.2\n",
      " 159 \tr_mean: -83.4 \tr_max: -67.3 \tr_min: -232.2\n",
      " 160 \tr_mean: -83.4 \tr_max: -67.3 \tr_min: -232.2\n",
      " 161 \tr_mean: -82.5 \tr_max: -67.3 \tr_min: -232.2\n",
      " 162 \tr_mean: -82.5 \tr_max: -67.3 \tr_min: -232.2\n",
      " 163 \tr_mean: -78.5 \tr_max: -67.3 \tr_min: -155.4\n",
      " 164 \tr_mean: -78.5 \tr_max: -67.3 \tr_min: -155.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 165 \tr_mean: -76.2 \tr_max: -67.3 \tr_min: -84.2\n",
      " 166 \tr_mean: -76.2 \tr_max: -67.3 \tr_min: -84.2\n",
      " 167 \tr_mean: -75.5 \tr_max: -67.3 \tr_min: -84.2\n",
      " 168 \tr_mean: -74.8 \tr_max: -62.9 \tr_min: -84.2\n",
      " 169 \tr_mean: -74.8 \tr_max: -62.9 \tr_min: -84.2\n",
      " 170 \tr_mean: -73.9 \tr_max: -62.9 \tr_min: -84.2\n",
      " 171 \tr_mean: -73.9 \tr_max: -62.9 \tr_min: -84.2\n",
      " 172 \tr_mean: -73.1 \tr_max: -57.4 \tr_min: -149.3\n",
      " 173 \tr_mean: -73.1 \tr_max: -57.4 \tr_min: -149.3\n",
      " 174 \tr_mean: -70.1 \tr_max: -57.1 \tr_min: -149.3\n",
      " 175 \tr_mean: -67.6 \tr_max: -55.1 \tr_min: -149.3\n",
      " 176 \tr_mean: -67.6 \tr_max: -55.1 \tr_min: -149.3\n",
      " 177 \tr_mean: -64.9 \tr_max: -51.1 \tr_min: -149.3\n",
      " 178 \tr_mean: -64.9 \tr_max: -51.1 \tr_min: -149.3\n",
      " 179 \tr_mean: -62.7 \tr_max: -51.1 \tr_min: -149.3\n",
      " 180 \tr_mean: -62.7 \tr_max: -51.1 \tr_min: -149.3\n",
      " 181 \tr_mean: -60.5 \tr_max: -48.9 \tr_min: -124.0\n",
      " 182 \tr_mean: -60.5 \tr_max: -48.9 \tr_min: -124.0\n",
      " 183 \tr_mean: -60.4 \tr_max: -48.9 \tr_min: -124.0\n",
      " 184 \tr_mean: -60.9 \tr_max: -48.9 \tr_min: -124.0\n",
      " 185 \tr_mean: -60.9 \tr_max: -48.9 \tr_min: -124.0\n",
      " 186 \tr_mean: -63.8 \tr_max: -48.9 \tr_min: -126.3\n",
      " 187 \tr_mean: -63.8 \tr_max: -48.9 \tr_min: -126.3\n",
      " 188 \tr_mean: -67.2 \tr_max: -44.9 \tr_min: -162.0\n",
      " 189 \tr_mean: -67.2 \tr_max: -44.9 \tr_min: -162.0\n",
      " 190 \tr_mean: -74.9 \tr_max: -44.9 \tr_min: -225.6\n",
      " 191 \tr_mean: -74.9 \tr_max: -44.9 \tr_min: -225.6\n",
      " 192 \tr_mean: -80.4 \tr_max: -43.8 \tr_min: -225.6\n",
      " 193 \tr_mean: -87.4 \tr_max: -43.8 \tr_min: -226.2\n",
      " 194 \tr_mean: -87.4 \tr_max: -43.8 \tr_min: -226.2\n",
      " 195 \tr_mean: -91.9 \tr_max: -43.8 \tr_min: -226.2\n",
      " 196 \tr_mean: -91.9 \tr_max: -43.8 \tr_min: -226.2\n",
      " 197 \tr_mean: -89.4 \tr_max: -43.8 \tr_min: -226.2\n",
      " 198 \tr_mean: -89.4 \tr_max: -43.8 \tr_min: -226.2\n",
      " 199 \tr_mean: -87.4 \tr_max: -43.8 \tr_min: -226.2\n",
      " 200 \tr_mean: -95.3 \tr_max: -44.1 \tr_min: -234.5\n",
      " 201 \tr_mean: -95.3 \tr_max: -44.1 \tr_min: -234.5\n",
      " 202 \tr_mean: -93.6 \tr_max: -44.1 \tr_min: -234.5\n",
      " 203 \tr_mean: -93.6 \tr_max: -44.1 \tr_min: -234.5\n",
      " 204 \tr_mean: -100.9 \tr_max: -49.8 \tr_min: -256.4\n",
      " 205 \tr_mean: -100.9 \tr_max: -49.8 \tr_min: -256.4\n",
      " 206 \tr_mean: -108.2 \tr_max: -48.2 \tr_min: -266.6\n",
      " 207 \tr_mean: -108.2 \tr_max: -48.2 \tr_min: -266.6\n",
      " 208 \tr_mean: -107.4 \tr_max: -44.0 \tr_min: -266.6\n",
      " 209 \tr_mean: -103.6 \tr_max: -42.1 \tr_min: -266.6\n",
      " 210 \tr_mean: -103.6 \tr_max: -42.1 \tr_min: -266.6\n",
      " 211 \tr_mean: -101.8 \tr_max: -42.1 \tr_min: -266.6\n",
      " 212 \tr_mean: -101.8 \tr_max: -42.1 \tr_min: -266.6\n",
      " 213 \tr_mean: -91.1 \tr_max: -42.1 \tr_min: -266.6\n",
      " 214 \tr_mean: -91.1 \tr_max: -42.1 \tr_min: -266.6\n",
      " 215 \tr_mean: -91.2 \tr_max: -42.1 \tr_min: -234.2\n",
      " 216 \tr_mean: -91.2 \tr_max: -42.1 \tr_min: -234.2\n",
      " 217 \tr_mean: -92.5 \tr_max: -42.1 \tr_min: -228.8\n",
      " 218 \tr_mean: -88.6 \tr_max: -43.2 \tr_min: -228.8\n",
      " 219 \tr_mean: -88.6 \tr_max: -43.2 \tr_min: -228.8\n",
      " 220 \tr_mean: -88.3 \tr_max: -42.8 \tr_min: -228.8\n",
      " 221 \tr_mean: -88.3 \tr_max: -42.8 \tr_min: -228.8\n",
      " 222 \tr_mean: -93.3 \tr_max: -42.8 \tr_min: -228.8\n",
      " 223 \tr_mean: -93.3 \tr_max: -42.8 \tr_min: -228.8\n",
      " 224 \tr_mean: -97.3 \tr_max: -42.8 \tr_min: -203.5\n",
      " 225 \tr_mean: -98.0 \tr_max: -42.8 \tr_min: -207.5\n",
      " 226 \tr_mean: -98.0 \tr_max: -42.8 \tr_min: -207.5\n",
      " 227 \tr_mean: -98.4 \tr_max: -41.3 \tr_min: -207.5\n",
      " 228 \tr_mean: -98.4 \tr_max: -41.3 \tr_min: -207.5\n",
      " 229 \tr_mean: -97.3 \tr_max: -41.3 \tr_min: -207.5\n",
      " 230 \tr_mean: -97.3 \tr_max: -41.3 \tr_min: -207.5\n",
      " 231 \tr_mean: -92.1 \tr_max: -41.3 \tr_min: -207.5\n",
      " 232 \tr_mean: -92.1 \tr_max: -41.3 \tr_min: -207.5\n",
      " 233 \tr_mean: -76.0 \tr_max: -18.7 \tr_min: -207.5\n",
      " 234 \tr_mean: -72.4 \tr_max: -18.7 \tr_min: -169.8\n",
      " 235 \tr_mean: -72.4 \tr_max: -18.7 \tr_min: -169.8\n",
      " 236 \tr_mean: -71.2 \tr_max: -18.7 \tr_min: -169.8\n",
      " 237 \tr_mean: -71.2 \tr_max: -18.7 \tr_min: -169.8\n",
      " 238 \tr_mean: -72.8 \tr_max: -18.7 \tr_min: -199.8\n",
      " 239 \tr_mean: -72.8 \tr_max: -18.7 \tr_min: -199.8\n",
      " 240 \tr_mean: -74.5 \tr_max: -18.7 \tr_min: -199.8\n",
      " 241 \tr_mean: -74.5 \tr_max: -18.7 \tr_min: -199.8\n",
      " 242 \tr_mean: -88.3 \tr_max: -42.8 \tr_min: -222.2\n",
      " 243 \tr_mean: -98.4 \tr_max: -42.8 \tr_min: -222.2\n",
      " 244 \tr_mean: -98.4 \tr_max: -42.8 \tr_min: -222.2\n",
      " 245 \tr_mean: -98.4 \tr_max: -43.3 \tr_min: -222.2\n",
      " 246 \tr_mean: -98.4 \tr_max: -43.3 \tr_min: -222.2\n",
      " 247 \tr_mean: -102.2 \tr_max: -50.0 \tr_min: -222.4\n",
      " 248 \tr_mean: -102.2 \tr_max: -50.0 \tr_min: -222.4\n",
      " 249 \tr_mean: -101.1 \tr_max: -17.7 \tr_min: -222.4\n",
      " 250 \tr_mean: -96.6 \tr_max: -17.7 \tr_min: -222.4\n",
      " 251 \tr_mean: -96.6 \tr_max: -17.7 \tr_min: -222.4\n",
      " 252 \tr_mean: -87.4 \tr_max: -17.7 \tr_min: -222.4\n",
      " 253 \tr_mean: -87.4 \tr_max: -17.7 \tr_min: -222.4\n",
      " 254 \tr_mean: -87.5 \tr_max: -17.7 \tr_min: -222.4\n",
      " 255 \tr_mean: -87.5 \tr_max: -17.7 \tr_min: -222.4\n",
      " 256 \tr_mean: -80.6 \tr_max: -17.7 \tr_min: -185.8\n",
      " 257 \tr_mean: -80.6 \tr_max: -17.7 \tr_min: -185.8\n",
      " 258 \tr_mean: -81.4 \tr_max: -40.8 \tr_min: -185.8\n",
      " 259 \tr_mean: -83.5 \tr_max: -40.8 \tr_min: -185.8\n",
      " 260 \tr_mean: -83.5 \tr_max: -40.8 \tr_min: -185.8\n",
      " 261 \tr_mean: -87.8 \tr_max: -39.0 \tr_min: -218.3\n",
      " 262 \tr_mean: -87.8 \tr_max: -39.0 \tr_min: -218.3\n",
      " 263 \tr_mean: -92.2 \tr_max: -32.5 \tr_min: -218.3\n",
      " 264 \tr_mean: -92.2 \tr_max: -32.5 \tr_min: -218.3\n",
      " 265 \tr_mean: -103.7 \tr_max: -31.3 \tr_min: -240.5\n",
      " 266 \tr_mean: -103.7 \tr_max: -31.3 \tr_min: -240.5\n",
      " 267 \tr_mean: -109.9 \tr_max: -31.3 \tr_min: -240.5\n",
      " 268 \tr_mean: -112.5 \tr_max: -31.3 \tr_min: -240.5\n",
      " 269 \tr_mean: -112.5 \tr_max: -31.3 \tr_min: -240.5\n",
      " 270 \tr_mean: -107.9 \tr_max: -31.3 \tr_min: -240.5\n",
      " 271 \tr_mean: -107.9 \tr_max: -31.3 \tr_min: -240.5\n",
      " 272 \tr_mean: -100.6 \tr_max: -31.3 \tr_min: -240.5\n",
      " 273 \tr_mean: -100.6 \tr_max: -31.3 \tr_min: -240.5\n",
      " 274 \tr_mean: -91.1 \tr_max: -38.7 \tr_min: -226.2\n",
      " 275 \tr_mean: -89.8 \tr_max: -40.8 \tr_min: -221.5\n",
      " 276 \tr_mean: -89.8 \tr_max: -40.8 \tr_min: -221.5\n",
      " 277 \tr_mean: -89.8 \tr_max: -35.9 \tr_min: -221.5\n",
      " 278 \tr_mean: -89.8 \tr_max: -35.9 \tr_min: -221.5\n",
      " 279 \tr_mean: -97.8 \tr_max: -35.9 \tr_min: -221.5\n",
      " 280 \tr_mean: -97.8 \tr_max: -35.9 \tr_min: -221.5\n",
      " 281 \tr_mean: -107.8 \tr_max: -35.9 \tr_min: -222.1\n",
      " 282 \tr_mean: -107.8 \tr_max: -35.9 \tr_min: -222.1\n",
      " 283 \tr_mean: -110.8 \tr_max: -35.9 \tr_min: -222.1\n",
      " 284 \tr_mean: -106.2 \tr_max: -35.9 \tr_min: -222.1\n",
      " 285 \tr_mean: -106.2 \tr_max: -35.9 \tr_min: -222.1\n",
      " 286 \tr_mean: -100.7 \tr_max: -47.5 \tr_min: -222.1\n",
      " 287 \tr_mean: -100.7 \tr_max: -47.5 \tr_min: -222.1\n",
      " 288 \tr_mean: -94.9 \tr_max: -51.5 \tr_min: -222.1\n",
      " 289 \tr_mean: -94.9 \tr_max: -51.5 \tr_min: -222.1\n",
      " 290 \tr_mean: -90.1 \tr_max: -53.4 \tr_min: -168.5\n",
      " 291 \tr_mean: -90.1 \tr_max: -53.4 \tr_min: -168.5\n",
      " 292 \tr_mean: -90.6 \tr_max: -50.0 \tr_min: -168.5\n",
      " 293 \tr_mean: -89.9 \tr_max: -46.0 \tr_min: -168.5\n",
      " 294 \tr_mean: -89.9 \tr_max: -46.0 \tr_min: -168.5\n",
      " 295 \tr_mean: -90.8 \tr_max: -45.3 \tr_min: -226.2\n",
      " 296 \tr_mean: -90.8 \tr_max: -45.3 \tr_min: -226.2\n",
      " 297 \tr_mean: -89.1 \tr_max: -45.3 \tr_min: -226.2\n",
      " 298 \tr_mean: -89.1 \tr_max: -45.3 \tr_min: -226.2\n",
      " 299 \tr_mean: -87.1 \tr_max: -45.3 \tr_min: -226.2\n",
      " 300 \tr_mean: -86.4 \tr_max: -45.3 \tr_min: -226.2\n",
      " 301 \tr_mean: -86.4 \tr_max: -45.3 \tr_min: -226.2\n",
      " 302 \tr_mean: -88.4 \tr_max: -41.2 \tr_min: -226.2\n",
      " 303 \tr_mean: -88.4 \tr_max: -41.2 \tr_min: -226.2\n",
      " 304 \tr_mean: -89.7 \tr_max: -41.2 \tr_min: -225.8\n",
      " 305 \tr_mean: -89.7 \tr_max: -41.2 \tr_min: -225.8\n",
      " 306 \tr_mean: -92.8 \tr_max: -41.2 \tr_min: -225.8\n",
      " 307 \tr_mean: -92.8 \tr_max: -41.2 \tr_min: -225.8\n",
      " 308 \tr_mean: -97.0 \tr_max: -41.2 \tr_min: -225.8\n",
      " 309 \tr_mean: -100.7 \tr_max: -41.2 \tr_min: -225.8\n",
      " 310 \tr_mean: -100.7 \tr_max: -41.2 \tr_min: -225.8\n",
      " 311 \tr_mean: -102.5 \tr_max: -42.7 \tr_min: -225.8\n",
      " 312 \tr_mean: -102.5 \tr_max: -42.7 \tr_min: -225.8\n",
      " 313 \tr_mean: -106.3 \tr_max: -48.8 \tr_min: -176.4\n",
      " 314 \tr_mean: -106.3 \tr_max: -48.8 \tr_min: -176.4\n",
      " 315 \tr_mean: -105.8 \tr_max: -59.1 \tr_min: -167.2\n",
      " 316 \tr_mean: -105.8 \tr_max: -59.1 \tr_min: -167.2\n",
      " 317 \tr_mean: -110.4 \tr_max: -56.7 \tr_min: -215.8\n",
      " 318 \tr_mean: -112.1 \tr_max: -48.8 \tr_min: -229.7\n",
      " 319 \tr_mean: -112.1 \tr_max: -48.8 \tr_min: -229.7\n",
      " 320 \tr_mean: -113.4 \tr_max: -48.8 \tr_min: -229.7\n",
      " 321 \tr_mean: -113.4 \tr_max: -48.8 \tr_min: -229.7\n",
      " 322 \tr_mean: -115.0 \tr_max: -48.8 \tr_min: -238.8\n",
      " 323 \tr_mean: -115.0 \tr_max: -48.8 \tr_min: -238.8\n",
      " 324 \tr_mean: -116.9 \tr_max: -48.8 \tr_min: -238.8\n",
      " 325 \tr_mean: -111.9 \tr_max: -45.6 \tr_min: -238.8\n",
      " 326 \tr_mean: -111.9 \tr_max: -45.6 \tr_min: -238.8\n",
      " 327 \tr_mean: -110.7 \tr_max: -45.6 \tr_min: -238.8\n",
      " 328 \tr_mean: -110.7 \tr_max: -45.6 \tr_min: -238.8\n",
      " 329 \tr_mean: -106.3 \tr_max: -45.6 \tr_min: -238.8\n",
      " 330 \tr_mean: -106.3 \tr_max: -45.6 \tr_min: -238.8\n",
      " 331 \tr_mean: -102.9 \tr_max: -45.6 \tr_min: -223.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 332 \tr_mean: -102.9 \tr_max: -45.6 \tr_min: -223.5\n",
      " 333 \tr_mean: -99.2 \tr_max: -45.4 \tr_min: -223.5\n",
      " 334 \tr_mean: -99.5 \tr_max: -45.4 \tr_min: -223.5\n",
      " 335 \tr_mean: -99.5 \tr_max: -45.4 \tr_min: -223.5\n",
      " 336 \tr_mean: -97.2 \tr_max: -45.4 \tr_min: -223.5\n",
      " 337 \tr_mean: -97.2 \tr_max: -45.4 \tr_min: -223.5\n",
      " 338 \tr_mean: -103.1 \tr_max: -45.4 \tr_min: -216.4\n",
      " 339 \tr_mean: -103.1 \tr_max: -45.4 \tr_min: -216.4\n",
      " 340 \tr_mean: -100.7 \tr_max: -45.4 \tr_min: -216.4\n",
      " 341 \tr_mean: -100.7 \tr_max: -45.4 \tr_min: -216.4\n",
      " 342 \tr_mean: -107.8 \tr_max: -45.5 \tr_min: -218.2\n",
      " 343 \tr_mean: -107.3 \tr_max: -45.5 \tr_min: -219.2\n",
      " 344 \tr_mean: -107.3 \tr_max: -45.5 \tr_min: -219.2\n",
      " 345 \tr_mean: -111.1 \tr_max: -45.5 \tr_min: -224.2\n",
      " 346 \tr_mean: -111.1 \tr_max: -45.5 \tr_min: -224.2\n",
      " 347 \tr_mean: -105.5 \tr_max: -31.7 \tr_min: -224.2\n",
      " 348 \tr_mean: -105.5 \tr_max: -31.7 \tr_min: -224.2\n",
      " 349 \tr_mean: -106.6 \tr_max: -31.7 \tr_min: -224.2\n",
      " 350 \tr_mean: -102.2 \tr_max: -31.7 \tr_min: -224.2\n",
      " 351 \tr_mean: -102.2 \tr_max: -31.7 \tr_min: -224.2\n",
      " 352 \tr_mean: -110.6 \tr_max: -31.7 \tr_min: -226.2\n",
      " 353 \tr_mean: -110.6 \tr_max: -31.7 \tr_min: -226.2\n",
      " 354 \tr_mean: -109.2 \tr_max: -31.7 \tr_min: -226.2\n",
      " 355 \tr_mean: -109.2 \tr_max: -31.7 \tr_min: -226.2\n",
      " 356 \tr_mean: -111.6 \tr_max: -31.7 \tr_min: -226.2\n",
      " 357 \tr_mean: -111.6 \tr_max: -31.7 \tr_min: -226.2\n",
      " 358 \tr_mean: -113.9 \tr_max: -43.4 \tr_min: -226.2\n",
      " 359 \tr_mean: -123.3 \tr_max: -43.4 \tr_min: -232.2\n",
      " 360 \tr_mean: -123.3 \tr_max: -43.4 \tr_min: -232.2\n",
      " 361 \tr_mean: -118.3 \tr_max: -45.4 \tr_min: -232.2\n",
      " 362 \tr_mean: -118.3 \tr_max: -45.4 \tr_min: -232.2\n",
      " 363 \tr_mean: -119.5 \tr_max: -43.7 \tr_min: -232.2\n",
      " 364 \tr_mean: -119.5 \tr_max: -43.7 \tr_min: -232.2\n",
      " 365 \tr_mean: -125.2 \tr_max: -39.3 \tr_min: -232.2\n",
      " 366 \tr_mean: -125.2 \tr_max: -39.3 \tr_min: -232.2\n",
      " 367 \tr_mean: -124.6 \tr_max: -39.3 \tr_min: -232.2\n",
      " 368 \tr_mean: -116.4 \tr_max: -39.3 \tr_min: -231.5\n",
      " 369 \tr_mean: -116.4 \tr_max: -39.3 \tr_min: -231.5\n",
      " 370 \tr_mean: -115.2 \tr_max: -39.3 \tr_min: -231.5\n",
      " 371 \tr_mean: -115.2 \tr_max: -39.3 \tr_min: -231.5\n",
      " 372 \tr_mean: -112.8 \tr_max: -39.3 \tr_min: -228.2\n",
      " 373 \tr_mean: -112.8 \tr_max: -39.3 \tr_min: -228.2\n",
      " 374 \tr_mean: -108.7 \tr_max: -45.1 \tr_min: -226.2\n",
      " 375 \tr_mean: -107.1 \tr_max: -45.1 \tr_min: -226.2\n",
      " 376 \tr_mean: -107.1 \tr_max: -45.1 \tr_min: -226.2\n",
      " 377 \tr_mean: -108.7 \tr_max: -43.0 \tr_min: -226.2\n",
      " 378 \tr_mean: -108.7 \tr_max: -43.0 \tr_min: -226.2\n",
      " 379 \tr_mean: -107.0 \tr_max: -43.0 \tr_min: -234.0\n",
      " 380 \tr_mean: -107.0 \tr_max: -43.0 \tr_min: -234.0\n",
      " 381 \tr_mean: -106.5 \tr_max: -43.0 \tr_min: -234.0\n",
      " 382 \tr_mean: -106.5 \tr_max: -43.0 \tr_min: -234.0\n",
      " 383 \tr_mean: -105.9 \tr_max: -43.0 \tr_min: -234.0\n",
      " 384 \tr_mean: -106.4 \tr_max: -43.0 \tr_min: -234.0\n",
      " 385 \tr_mean: -106.4 \tr_max: -43.0 \tr_min: -234.0\n",
      " 386 \tr_mean: -106.0 \tr_max: -42.6 \tr_min: -234.0\n",
      " 387 \tr_mean: -106.0 \tr_max: -42.6 \tr_min: -234.0\n",
      " 388 \tr_mean: -103.1 \tr_max: -42.6 \tr_min: -219.2\n",
      " 389 \tr_mean: -103.1 \tr_max: -42.6 \tr_min: -219.2\n",
      " 390 \tr_mean: -105.1 \tr_max: -38.9 \tr_min: -226.2\n",
      " 391 \tr_mean: -105.1 \tr_max: -38.9 \tr_min: -226.2\n",
      " 392 \tr_mean: -104.0 \tr_max: -38.9 \tr_min: -226.2\n",
      " 393 \tr_mean: -108.3 \tr_max: -38.9 \tr_min: -226.2\n",
      " 394 \tr_mean: -108.3 \tr_max: -38.9 \tr_min: -226.2\n",
      " 395 \tr_mean: -109.4 \tr_max: -38.9 \tr_min: -227.3\n",
      " 396 \tr_mean: -109.4 \tr_max: -38.9 \tr_min: -227.3\n",
      " 397 \tr_mean: -111.6 \tr_max: -38.9 \tr_min: -227.3\n",
      " 398 \tr_mean: -111.6 \tr_max: -38.9 \tr_min: -227.3\n",
      " 399 \tr_mean: -107.5 \tr_max: -38.9 \tr_min: -227.3\n",
      " 400 \tr_mean: -114.5 \tr_max: -38.9 \tr_min: -227.3\n",
      " 401 \tr_mean: -114.5 \tr_max: -38.9 \tr_min: -227.3\n",
      " 402 \tr_mean: -111.9 \tr_max: -38.9 \tr_min: -227.3\n",
      " 403 \tr_mean: -111.9 \tr_max: -38.9 \tr_min: -227.3\n",
      " 404 \tr_mean: -108.2 \tr_max: -38.9 \tr_min: -226.4\n",
      " 405 \tr_mean: -108.2 \tr_max: -38.9 \tr_min: -226.4\n",
      " 406 \tr_mean: -110.4 \tr_max: -38.9 \tr_min: -224.2\n",
      " 407 \tr_mean: -110.4 \tr_max: -38.9 \tr_min: -224.2\n",
      " 408 \tr_mean: -111.7 \tr_max: -38.9 \tr_min: -224.2\n",
      " 409 \tr_mean: -106.1 \tr_max: -38.9 \tr_min: -224.2\n",
      " 410 \tr_mean: -106.1 \tr_max: -38.9 \tr_min: -224.2\n",
      " 411 \tr_mean: -110.0 \tr_max: -38.9 \tr_min: -229.1\n",
      " 412 \tr_mean: -110.0 \tr_max: -38.9 \tr_min: -229.1\n",
      " 413 \tr_mean: -113.2 \tr_max: -40.9 \tr_min: -229.1\n",
      " 414 \tr_mean: -113.2 \tr_max: -40.9 \tr_min: -229.1\n",
      " 415 \tr_mean: -113.4 \tr_max: -40.9 \tr_min: -229.1\n",
      " 416 \tr_mean: -113.4 \tr_max: -40.9 \tr_min: -229.1\n",
      " 417 \tr_mean: -120.4 \tr_max: -45.8 \tr_min: -235.8\n",
      " 418 \tr_mean: -124.3 \tr_max: -45.8 \tr_min: -235.8\n",
      " 419 \tr_mean: -124.3 \tr_max: -45.8 \tr_min: -235.8\n",
      " 420 \tr_mean: -122.3 \tr_max: -45.8 \tr_min: -235.8\n",
      " 421 \tr_mean: -122.3 \tr_max: -45.8 \tr_min: -235.8\n",
      " 422 \tr_mean: -121.6 \tr_max: -46.1 \tr_min: -235.8\n",
      " 423 \tr_mean: -121.6 \tr_max: -46.1 \tr_min: -235.8\n",
      " 424 \tr_mean: -123.0 \tr_max: -44.5 \tr_min: -235.8\n",
      " 425 \tr_mean: -115.0 \tr_max: -44.5 \tr_min: -229.2\n",
      " 426 \tr_mean: -115.0 \tr_max: -44.5 \tr_min: -229.2\n",
      " 427 \tr_mean: -113.3 \tr_max: -44.5 \tr_min: -223.5\n",
      " 428 \tr_mean: -113.3 \tr_max: -44.5 \tr_min: -223.5\n",
      " 429 \tr_mean: -112.0 \tr_max: -43.5 \tr_min: -223.5\n",
      " 430 \tr_mean: -112.0 \tr_max: -43.5 \tr_min: -223.5\n",
      " 431 \tr_mean: -113.0 \tr_max: -41.9 \tr_min: -223.5\n",
      " 432 \tr_mean: -113.0 \tr_max: -41.9 \tr_min: -223.5\n",
      " 433 \tr_mean: -111.7 \tr_max: -41.9 \tr_min: -216.9\n",
      " 434 \tr_mean: -112.2 \tr_max: -41.9 \tr_min: -225.2\n",
      " 435 \tr_mean: -112.2 \tr_max: -41.9 \tr_min: -225.2\n",
      " 436 \tr_mean: -115.0 \tr_max: -41.9 \tr_min: -225.2\n",
      " 437 \tr_mean: -115.0 \tr_max: -41.9 \tr_min: -225.2\n",
      " 438 \tr_mean: -112.6 \tr_max: -41.9 \tr_min: -225.2\n",
      " 439 \tr_mean: -112.6 \tr_max: -41.9 \tr_min: -225.2\n",
      " 440 \tr_mean: -108.7 \tr_max: -43.3 \tr_min: -225.2\n",
      " 441 \tr_mean: -108.7 \tr_max: -43.3 \tr_min: -225.2\n",
      " 442 \tr_mean: -106.4 \tr_max: -44.5 \tr_min: -225.2\n",
      " 443 \tr_mean: -111.0 \tr_max: -44.5 \tr_min: -228.8\n",
      " 444 \tr_mean: -111.0 \tr_max: -44.5 \tr_min: -228.8\n",
      " 445 \tr_mean: -106.4 \tr_max: -44.5 \tr_min: -228.8\n",
      " 446 \tr_mean: -106.4 \tr_max: -44.5 \tr_min: -228.8\n",
      " 447 \tr_mean: -105.6 \tr_max: -43.6 \tr_min: -228.8\n",
      " 448 \tr_mean: -105.6 \tr_max: -43.6 \tr_min: -228.8\n",
      " 449 \tr_mean: -108.1 \tr_max: -41.0 \tr_min: -228.8\n",
      " 450 \tr_mean: -110.5 \tr_max: -41.0 \tr_min: -228.8\n",
      " 451 \tr_mean: -110.5 \tr_max: -41.0 \tr_min: -228.8\n",
      " 452 \tr_mean: -104.0 \tr_max: -21.7 \tr_min: -219.4\n",
      " 453 \tr_mean: -104.0 \tr_max: -21.7 \tr_min: -219.4\n",
      " 454 \tr_mean: -103.8 \tr_max: -21.7 \tr_min: -219.4\n",
      " 455 \tr_mean: -103.8 \tr_max: -21.7 \tr_min: -219.4\n",
      " 456 \tr_mean: -108.3 \tr_max: -21.7 \tr_min: -235.7\n",
      " 457 \tr_mean: -108.3 \tr_max: -21.7 \tr_min: -235.7\n",
      " 458 \tr_mean: -104.3 \tr_max: -18.5 \tr_min: -235.7\n",
      " 459 \tr_mean: -101.5 \tr_max: -18.5 \tr_min: -235.7\n",
      " 460 \tr_mean: -101.5 \tr_max: -18.5 \tr_min: -235.7\n",
      " 461 \tr_mean: -107.5 \tr_max: -18.5 \tr_min: -235.7\n",
      " 462 \tr_mean: -107.5 \tr_max: -18.5 \tr_min: -235.7\n",
      " 463 \tr_mean: -111.1 \tr_max: -18.5 \tr_min: -235.7\n",
      " 464 \tr_mean: -111.1 \tr_max: -18.5 \tr_min: -235.7\n",
      " 465 \tr_mean: -106.7 \tr_max: -18.5 \tr_min: -231.0\n",
      " 466 \tr_mean: -106.7 \tr_max: -18.5 \tr_min: -231.0\n",
      " 467 \tr_mean: -110.1 \tr_max: -37.2 \tr_min: -231.0\n",
      " 468 \tr_mean: -112.9 \tr_max: -43.5 \tr_min: -231.0\n",
      " 469 \tr_mean: -112.9 \tr_max: -43.5 \tr_min: -231.0\n",
      " 470 \tr_mean: -114.1 \tr_max: -43.5 \tr_min: -231.0\n",
      " 471 \tr_mean: -114.1 \tr_max: -43.5 \tr_min: -231.0\n",
      " 472 \tr_mean: -112.0 \tr_max: -42.6 \tr_min: -229.6\n",
      " 473 \tr_mean: -112.0 \tr_max: -42.6 \tr_min: -229.6\n",
      " 474 \tr_mean: -111.3 \tr_max: -42.6 \tr_min: -229.6\n",
      " 475 \tr_mean: -114.2 \tr_max: -42.6 \tr_min: -229.6\n",
      " 476 \tr_mean: -114.2 \tr_max: -42.6 \tr_min: -229.6\n",
      " 477 \tr_mean: -108.2 \tr_max: -42.1 \tr_min: -227.7\n",
      " 478 \tr_mean: -108.2 \tr_max: -42.1 \tr_min: -227.7\n",
      " 479 \tr_mean: -103.2 \tr_max: -42.1 \tr_min: -227.7\n",
      " 480 \tr_mean: -103.2 \tr_max: -42.1 \tr_min: -227.7\n",
      " 481 \tr_mean: -105.9 \tr_max: -42.1 \tr_min: -219.2\n",
      " 482 \tr_mean: -105.9 \tr_max: -42.1 \tr_min: -219.2\n",
      " 483 \tr_mean: -107.1 \tr_max: -42.1 \tr_min: -219.2\n",
      " 484 \tr_mean: -112.3 \tr_max: -42.1 \tr_min: -229.6\n",
      " 485 \tr_mean: -112.3 \tr_max: -42.1 \tr_min: -229.6\n",
      " 486 \tr_mean: -116.9 \tr_max: -25.6 \tr_min: -229.6\n",
      " 487 \tr_mean: -116.9 \tr_max: -25.6 \tr_min: -229.6\n",
      " 488 \tr_mean: -116.2 \tr_max: -25.6 \tr_min: -229.6\n",
      " 489 \tr_mean: -116.2 \tr_max: -25.6 \tr_min: -229.6\n",
      " 490 \tr_mean: -105.3 \tr_max: -25.6 \tr_min: -229.6\n",
      " 491 \tr_mean: -105.3 \tr_max: -25.6 \tr_min: -229.6\n",
      " 492 \tr_mean: -107.4 \tr_max: -25.6 \tr_min: -229.6\n",
      " 493 \tr_mean: -94.0 \tr_max: -25.6 \tr_min: -229.4\n",
      " 494 \tr_mean: -94.0 \tr_max: -25.6 \tr_min: -229.4\n",
      " 495 \tr_mean: -90.4 \tr_max: -27.5 \tr_min: -223.4\n",
      " 496 \tr_mean: -90.4 \tr_max: -27.5 \tr_min: -223.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 497 \tr_mean: -92.0 \tr_max: -27.5 \tr_min: -222.2\n",
      " 498 \tr_mean: -92.0 \tr_max: -27.5 \tr_min: -222.2\n",
      " 499 \tr_mean: -97.8 \tr_max: -32.7 \tr_min: -227.4\n",
      " 500 \tr_mean: -95.0 \tr_max: -32.7 \tr_min: -227.4\n",
      " 501 \tr_mean: -95.0 \tr_max: -32.7 \tr_min: -227.4\n",
      " 502 \tr_mean: -100.5 \tr_max: -33.6 \tr_min: -227.4\n",
      " 503 \tr_mean: -100.5 \tr_max: -33.6 \tr_min: -227.4\n",
      " 504 \tr_mean: -101.6 \tr_max: -33.6 \tr_min: -227.4\n",
      " 505 \tr_mean: -101.6 \tr_max: -33.6 \tr_min: -227.4\n",
      " 506 \tr_mean: -102.6 \tr_max: -31.0 \tr_min: -227.4\n",
      " 507 \tr_mean: -102.6 \tr_max: -31.0 \tr_min: -227.4\n",
      " 508 \tr_mean: -102.6 \tr_max: -28.4 \tr_min: -222.6\n",
      " 509 \tr_mean: -103.7 \tr_max: -28.4 \tr_min: -222.6\n",
      " 510 \tr_mean: -103.7 \tr_max: -28.4 \tr_min: -222.6\n",
      " 511 \tr_mean: -98.1 \tr_max: -28.4 \tr_min: -209.7\n",
      " 512 \tr_mean: -98.1 \tr_max: -28.4 \tr_min: -209.7\n",
      " 513 \tr_mean: -96.5 \tr_max: -28.4 \tr_min: -209.7\n",
      " 514 \tr_mean: -96.5 \tr_max: -28.4 \tr_min: -209.7\n",
      " 515 \tr_mean: -96.8 \tr_max: -28.4 \tr_min: -214.1\n",
      " 516 \tr_mean: -96.8 \tr_max: -28.4 \tr_min: -214.1\n",
      " 517 \tr_mean: -96.2 \tr_max: -31.6 \tr_min: -214.1\n",
      " 518 \tr_mean: -97.6 \tr_max: -31.6 \tr_min: -214.1\n",
      " 519 \tr_mean: -97.6 \tr_max: -31.6 \tr_min: -214.1\n",
      " 520 \tr_mean: -103.7 \tr_max: -31.1 \tr_min: -237.8\n",
      " 521 \tr_mean: -103.7 \tr_max: -31.1 \tr_min: -237.8\n",
      " 522 \tr_mean: -107.5 \tr_max: -25.1 \tr_min: -237.8\n",
      " 523 \tr_mean: -107.5 \tr_max: -25.1 \tr_min: -237.8\n",
      " 524 \tr_mean: -105.1 \tr_max: -25.1 \tr_min: -237.8\n",
      " 525 \tr_mean: -104.7 \tr_max: -25.1 \tr_min: -237.8\n",
      " 526 \tr_mean: -104.7 \tr_max: -25.1 \tr_min: -237.8\n",
      " 527 \tr_mean: -102.8 \tr_max: -13.8 \tr_min: -237.8\n",
      " 528 \tr_mean: -102.8 \tr_max: -13.8 \tr_min: -237.8\n",
      " 529 \tr_mean: -99.3 \tr_max: -13.8 \tr_min: -237.7\n",
      " 530 \tr_mean: -99.3 \tr_max: -13.8 \tr_min: -237.7\n",
      " 531 \tr_mean: -96.3 \tr_max: -13.8 \tr_min: -237.7\n",
      " 532 \tr_mean: -96.3 \tr_max: -13.8 \tr_min: -237.7\n",
      " 533 \tr_mean: -94.4 \tr_max: -13.8 \tr_min: -237.7\n",
      " 534 \tr_mean: -96.5 \tr_max: -13.8 \tr_min: -219.7\n",
      " 535 \tr_mean: -96.5 \tr_max: -13.8 \tr_min: -219.7\n",
      " 536 \tr_mean: -96.9 \tr_max: -29.3 \tr_min: -219.7\n",
      " 537 \tr_mean: -96.9 \tr_max: -29.3 \tr_min: -219.7\n",
      " 538 \tr_mean: -96.4 \tr_max: -29.3 \tr_min: -219.7\n",
      " 539 \tr_mean: -96.4 \tr_max: -29.3 \tr_min: -219.7\n",
      " 540 \tr_mean: -93.5 \tr_max: -29.3 \tr_min: -219.7\n",
      " 541 \tr_mean: -93.5 \tr_max: -29.3 \tr_min: -219.7\n",
      " 542 \tr_mean: -92.7 \tr_max: -29.3 \tr_min: -215.3\n",
      " 543 \tr_mean: -90.7 \tr_max: -29.3 \tr_min: -237.8\n",
      " 544 \tr_mean: -90.7 \tr_max: -29.3 \tr_min: -237.8\n",
      " 545 \tr_mean: -93.9 \tr_max: -32.4 \tr_min: -237.8\n",
      " 546 \tr_mean: -93.9 \tr_max: -32.4 \tr_min: -237.8\n",
      " 547 \tr_mean: -99.4 \tr_max: -32.4 \tr_min: -237.8\n",
      " 548 \tr_mean: -99.4 \tr_max: -32.4 \tr_min: -237.8\n",
      " 549 \tr_mean: -104.5 \tr_max: -32.4 \tr_min: -237.8\n",
      " 550 \tr_mean: -103.6 \tr_max: -32.4 \tr_min: -237.8\n",
      " 551 \tr_mean: -103.6 \tr_max: -32.4 \tr_min: -237.8\n",
      " 552 \tr_mean: -101.2 \tr_max: -32.4 \tr_min: -237.8\n",
      " 553 \tr_mean: -101.2 \tr_max: -32.4 \tr_min: -237.8\n",
      " 554 \tr_mean: -95.1 \tr_max: -32.4 \tr_min: -237.8\n",
      " 555 \tr_mean: -95.1 \tr_max: -32.4 \tr_min: -237.8\n",
      " 556 \tr_mean: -89.1 \tr_max: -36.0 \tr_min: -215.3\n",
      " 557 \tr_mean: -89.1 \tr_max: -36.0 \tr_min: -215.3\n",
      " 558 \tr_mean: -84.8 \tr_max: -36.0 \tr_min: -204.7\n",
      " 559 \tr_mean: -89.2 \tr_max: -36.0 \tr_min: -215.7\n",
      " 560 \tr_mean: -89.2 \tr_max: -36.0 \tr_min: -215.7\n",
      " 561 \tr_mean: -92.1 \tr_max: -2.5 \tr_min: -215.7\n",
      " 562 \tr_mean: -92.1 \tr_max: -2.5 \tr_min: -215.7\n",
      " 563 \tr_mean: -96.1 \tr_max: -2.5 \tr_min: -215.7\n",
      " 564 \tr_mean: -96.1 \tr_max: -2.5 \tr_min: -215.7\n",
      " 565 \tr_mean: -102.3 \tr_max: -2.5 \tr_min: -217.2\n",
      " 566 \tr_mean: -102.3 \tr_max: -2.5 \tr_min: -217.2\n",
      " 567 \tr_mean: -105.5 \tr_max: -2.5 \tr_min: -217.2\n",
      " 568 \tr_mean: -105.7 \tr_max: -2.5 \tr_min: -238.7\n",
      " 569 \tr_mean: -105.7 \tr_max: -2.5 \tr_min: -238.7\n",
      " 570 \tr_mean: -109.3 \tr_max: -35.1 \tr_min: -238.7\n",
      " 571 \tr_mean: -109.3 \tr_max: -35.1 \tr_min: -238.7\n",
      " 572 \tr_mean: -105.5 \tr_max: -35.1 \tr_min: -238.7\n",
      " 573 \tr_mean: -105.5 \tr_max: -35.1 \tr_min: -238.7\n",
      " 574 \tr_mean: -102.8 \tr_max: -35.1 \tr_min: -238.7\n",
      " 575 \tr_mean: -103.1 \tr_max: -39.8 \tr_min: -238.7\n",
      " 576 \tr_mean: -103.1 \tr_max: -39.8 \tr_min: -238.7\n",
      " 577 \tr_mean: -104.8 \tr_max: -36.8 \tr_min: -220.8\n",
      " 578 \tr_mean: -104.8 \tr_max: -36.8 \tr_min: -220.8\n",
      " 579 \tr_mean: -101.0 \tr_max: -32.5 \tr_min: -218.2\n",
      " 580 \tr_mean: -101.0 \tr_max: -32.5 \tr_min: -218.2\n",
      " 581 \tr_mean: -106.7 \tr_max: -32.5 \tr_min: -238.8\n",
      " 582 \tr_mean: -106.7 \tr_max: -32.5 \tr_min: -238.8\n",
      " 583 \tr_mean: -105.0 \tr_max: -25.3 \tr_min: -238.8\n",
      " 584 \tr_mean: -110.0 \tr_max: -25.3 \tr_min: -238.8\n",
      " 585 \tr_mean: -110.0 \tr_max: -25.3 \tr_min: -238.8\n",
      " 586 \tr_mean: -113.8 \tr_max: -25.3 \tr_min: -238.8\n",
      " 587 \tr_mean: -113.8 \tr_max: -25.3 \tr_min: -238.8\n",
      " 588 \tr_mean: -117.6 \tr_max: -25.3 \tr_min: -238.8\n",
      " 589 \tr_mean: -117.6 \tr_max: -25.3 \tr_min: -238.8\n",
      " 590 \tr_mean: -117.1 \tr_max: -25.3 \tr_min: -250.5\n",
      " 591 \tr_mean: -117.1 \tr_max: -25.3 \tr_min: -250.5\n",
      " 592 \tr_mean: -125.0 \tr_max: -33.2 \tr_min: -250.5\n",
      " 593 \tr_mean: -123.4 \tr_max: -33.2 \tr_min: -250.5\n",
      " 594 \tr_mean: -123.4 \tr_max: -33.2 \tr_min: -250.5\n",
      " 595 \tr_mean: -115.9 \tr_max: -33.2 \tr_min: -250.5\n",
      " 596 \tr_mean: -115.9 \tr_max: -33.2 \tr_min: -250.5\n",
      " 597 \tr_mean: -113.5 \tr_max: -33.2 \tr_min: -250.5\n",
      " 598 \tr_mean: -113.5 \tr_max: -33.2 \tr_min: -250.5\n",
      " 599 \tr_mean: -110.3 \tr_max: -22.3 \tr_min: -238.7\n",
      " 600 \tr_mean: -100.9 \tr_max: -22.3 \tr_min: -238.7\n",
      " 601 \tr_mean: -100.9 \tr_max: -22.3 \tr_min: -238.7\n",
      " 602 \tr_mean: -96.6 \tr_max: -22.3 \tr_min: -238.7\n",
      " 603 \tr_mean: -96.6 \tr_max: -22.3 \tr_min: -238.7\n",
      " 604 \tr_mean: -94.9 \tr_max: -22.3 \tr_min: -238.7\n",
      " 605 \tr_mean: -94.9 \tr_max: -22.3 \tr_min: -238.7\n",
      " 606 \tr_mean: -93.3 \tr_max: -22.3 \tr_min: -238.7\n",
      " 607 \tr_mean: -93.3 \tr_max: -22.3 \tr_min: -238.7\n",
      " 608 \tr_mean: -97.1 \tr_max: -27.6 \tr_min: -226.5\n",
      " 609 \tr_mean: -99.1 \tr_max: -38.3 \tr_min: -226.5\n",
      " 610 \tr_mean: -99.1 \tr_max: -38.3 \tr_min: -226.5\n",
      " 611 \tr_mean: -100.6 \tr_max: -38.3 \tr_min: -226.5\n",
      " 612 \tr_mean: -100.6 \tr_max: -38.3 \tr_min: -226.5\n",
      " 613 \tr_mean: -103.4 \tr_max: -36.9 \tr_min: -226.5\n",
      " 614 \tr_mean: -103.4 \tr_max: -36.9 \tr_min: -226.5\n",
      " 615 \tr_mean: -108.0 \tr_max: -36.9 \tr_min: -221.7\n",
      " 616 \tr_mean: -108.0 \tr_max: -36.9 \tr_min: -221.7\n",
      " 617 \tr_mean: -104.1 \tr_max: -36.9 \tr_min: -221.7\n",
      " 618 \tr_mean: -105.1 \tr_max: -36.9 \tr_min: -221.7\n",
      " 619 \tr_mean: -105.1 \tr_max: -36.9 \tr_min: -221.7\n",
      " 620 \tr_mean: -108.3 \tr_max: -36.9 \tr_min: -221.7\n",
      " 621 \tr_mean: -108.3 \tr_max: -36.9 \tr_min: -221.7\n",
      " 622 \tr_mean: -105.0 \tr_max: -36.1 \tr_min: -221.7\n",
      " 623 \tr_mean: -105.0 \tr_max: -36.1 \tr_min: -221.7\n",
      " 624 \tr_mean: -102.2 \tr_max: -36.1 \tr_min: -211.8\n",
      " 625 \tr_mean: -102.9 \tr_max: -36.1 \tr_min: -211.8\n",
      " 626 \tr_mean: -102.9 \tr_max: -36.1 \tr_min: -211.8\n",
      " 627 \tr_mean: -103.0 \tr_max: -34.8 \tr_min: -231.8\n",
      " 628 \tr_mean: -103.0 \tr_max: -34.8 \tr_min: -231.8\n",
      " 629 \tr_mean: -98.7 \tr_max: -34.8 \tr_min: -231.8\n",
      " 630 \tr_mean: -98.7 \tr_max: -34.8 \tr_min: -231.8\n",
      " 631 \tr_mean: -101.3 \tr_max: -34.8 \tr_min: -231.8\n",
      " 632 \tr_mean: -101.3 \tr_max: -34.8 \tr_min: -231.8\n",
      " 633 \tr_mean: -98.8 \tr_max: -34.8 \tr_min: -231.8\n",
      " 634 \tr_mean: -100.1 \tr_max: -34.8 \tr_min: -231.8\n",
      " 635 \tr_mean: -100.1 \tr_max: -34.8 \tr_min: -231.8\n",
      " 636 \tr_mean: -98.4 \tr_max: -39.3 \tr_min: -223.8\n",
      " 637 \tr_mean: -98.4 \tr_max: -39.3 \tr_min: -223.8\n",
      " 638 \tr_mean: -100.8 \tr_max: -36.8 \tr_min: -223.8\n",
      " 639 \tr_mean: -100.8 \tr_max: -36.8 \tr_min: -223.8\n",
      " 640 \tr_mean: -101.8 \tr_max: -35.7 \tr_min: -223.8\n",
      " 641 \tr_mean: -101.8 \tr_max: -35.7 \tr_min: -223.8\n",
      " 642 \tr_mean: -102.3 \tr_max: -25.2 \tr_min: -223.8\n",
      " 643 \tr_mean: -103.3 \tr_max: -25.2 \tr_min: -229.8\n",
      " 644 \tr_mean: -103.3 \tr_max: -25.2 \tr_min: -229.8\n",
      " 645 \tr_mean: -104.2 \tr_max: -25.2 \tr_min: -229.8\n",
      " 646 \tr_mean: -104.2 \tr_max: -25.2 \tr_min: -229.8\n",
      " 647 \tr_mean: -101.8 \tr_max: -25.2 \tr_min: -229.8\n",
      " 648 \tr_mean: -101.8 \tr_max: -25.2 \tr_min: -229.8\n",
      " 649 \tr_mean: -96.4 \tr_max: -25.2 \tr_min: -229.8\n",
      " 650 \tr_mean: -101.1 \tr_max: -42.0 \tr_min: -232.8\n",
      " 651 \tr_mean: -101.1 \tr_max: -42.0 \tr_min: -232.8\n",
      " 652 \tr_mean: -98.3 \tr_max: -42.0 \tr_min: -232.8\n",
      " 653 \tr_mean: -98.3 \tr_max: -42.0 \tr_min: -232.8\n",
      " 654 \tr_mean: -97.3 \tr_max: -22.4 \tr_min: -232.8\n",
      " 655 \tr_mean: -97.3 \tr_max: -22.4 \tr_min: -232.8\n",
      " 656 \tr_mean: -96.0 \tr_max: -22.4 \tr_min: -232.8\n",
      " 657 \tr_mean: -96.0 \tr_max: -22.4 \tr_min: -232.8\n",
      " 658 \tr_mean: -100.9 \tr_max: -22.4 \tr_min: -232.8\n",
      " 659 \tr_mean: -93.4 \tr_max: -22.4 \tr_min: -232.5\n",
      " 660 \tr_mean: -93.4 \tr_max: -22.4 \tr_min: -232.5\n",
      " 661 \tr_mean: -93.5 \tr_max: -4.7 \tr_min: -232.5\n",
      " 662 \tr_mean: -93.5 \tr_max: -4.7 \tr_min: -232.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 663 \tr_mean: -99.7 \tr_max: -4.7 \tr_min: -232.5\n",
      " 664 \tr_mean: -99.7 \tr_max: -4.7 \tr_min: -232.5\n",
      " 665 \tr_mean: -102.3 \tr_max: -4.7 \tr_min: -232.5\n",
      " 666 \tr_mean: -102.3 \tr_max: -4.7 \tr_min: -232.5\n",
      " 667 \tr_mean: -101.4 \tr_max: -4.7 \tr_min: -232.5\n",
      " 668 \tr_mean: -106.4 \tr_max: -4.7 \tr_min: -221.5\n",
      " 669 \tr_mean: -106.4 \tr_max: -4.7 \tr_min: -221.5\n",
      " 670 \tr_mean: -109.3 \tr_max: -20.7 \tr_min: -223.8\n",
      " 671 \tr_mean: -109.3 \tr_max: -20.7 \tr_min: -223.8\n",
      " 672 \tr_mean: -104.2 \tr_max: -20.7 \tr_min: -223.8\n",
      " 673 \tr_mean: -104.2 \tr_max: -20.7 \tr_min: -223.8\n",
      " 674 \tr_mean: -103.4 \tr_max: -22.6 \tr_min: -223.8\n",
      " 675 \tr_mean: -104.9 \tr_max: -22.6 \tr_min: -228.5\n",
      " 676 \tr_mean: -104.9 \tr_max: -22.6 \tr_min: -228.5\n",
      " 677 \tr_mean: -106.2 \tr_max: -22.6 \tr_min: -228.5\n",
      " 678 \tr_mean: -106.2 \tr_max: -22.6 \tr_min: -228.5\n",
      " 679 \tr_mean: -105.9 \tr_max: -22.6 \tr_min: -228.5\n",
      " 680 \tr_mean: -105.9 \tr_max: -22.6 \tr_min: -228.5\n",
      " 681 \tr_mean: -108.5 \tr_max: -22.6 \tr_min: -228.5\n",
      " 682 \tr_mean: -108.5 \tr_max: -22.6 \tr_min: -228.5\n",
      " 683 \tr_mean: -110.7 \tr_max: -31.2 \tr_min: -228.5\n",
      " 684 \tr_mean: -111.2 \tr_max: -31.2 \tr_min: -226.7\n",
      " 685 \tr_mean: -111.2 \tr_max: -31.2 \tr_min: -226.7\n",
      " 686 \tr_mean: -109.3 \tr_max: -28.0 \tr_min: -226.7\n",
      " 687 \tr_mean: -109.3 \tr_max: -28.0 \tr_min: -226.7\n",
      " 688 \tr_mean: -108.1 \tr_max: -28.0 \tr_min: -216.6\n",
      " 689 \tr_mean: -108.1 \tr_max: -28.0 \tr_min: -216.6\n",
      " 690 \tr_mean: -110.3 \tr_max: -28.0 \tr_min: -213.2\n",
      " 691 \tr_mean: -110.3 \tr_max: -28.0 \tr_min: -213.2\n",
      " 692 \tr_mean: -109.9 \tr_max: -24.7 \tr_min: -229.7\n",
      " 693 \tr_mean: -109.7 \tr_max: -24.7 \tr_min: -229.7\n",
      " 694 \tr_mean: -109.7 \tr_max: -24.7 \tr_min: -229.7\n",
      " 695 \tr_mean: -108.3 \tr_max: -24.7 \tr_min: -229.7\n",
      " 696 \tr_mean: -108.3 \tr_max: -24.7 \tr_min: -229.7\n",
      " 697 \tr_mean: -104.6 \tr_max: -24.7 \tr_min: -229.7\n",
      " 698 \tr_mean: -104.6 \tr_max: -24.7 \tr_min: -229.7\n",
      " 699 \tr_mean: -99.4 \tr_max: -24.7 \tr_min: -229.7\n",
      " 700 \tr_mean: -99.8 \tr_max: -38.0 \tr_min: -205.7\n",
      " 701 \tr_mean: -99.8 \tr_max: -38.0 \tr_min: -205.7\n",
      " 702 \tr_mean: -93.7 \tr_max: -38.0 \tr_min: -205.7\n",
      " 703 \tr_mean: -93.7 \tr_max: -38.0 \tr_min: -205.7\n",
      " 704 \tr_mean: -90.7 \tr_max: -37.5 \tr_min: -205.7\n",
      " 705 \tr_mean: -90.7 \tr_max: -37.5 \tr_min: -205.7\n",
      " 706 \tr_mean: -93.5 \tr_max: -27.1 \tr_min: -205.7\n",
      " 707 \tr_mean: -93.5 \tr_max: -27.1 \tr_min: -205.7\n",
      " 708 \tr_mean: -96.8 \tr_max: -27.1 \tr_min: -219.9\n",
      " 709 \tr_mean: -94.0 \tr_max: -27.1 \tr_min: -219.9\n",
      " 710 \tr_mean: -94.0 \tr_max: -27.1 \tr_min: -219.9\n",
      " 711 \tr_mean: -101.2 \tr_max: -27.1 \tr_min: -219.9\n",
      " 712 \tr_mean: -101.2 \tr_max: -27.1 \tr_min: -219.9\n",
      " 713 \tr_mean: -106.8 \tr_max: -27.1 \tr_min: -221.2\n",
      " 714 \tr_mean: -106.8 \tr_max: -27.1 \tr_min: -221.2\n",
      " 715 \tr_mean: -107.0 \tr_max: -27.3 \tr_min: -221.2\n",
      " 716 \tr_mean: -107.0 \tr_max: -27.3 \tr_min: -221.2\n",
      " 717 \tr_mean: -103.7 \tr_max: -27.2 \tr_min: -221.2\n",
      " 718 \tr_mean: -103.9 \tr_max: -27.2 \tr_min: -221.2\n",
      " 719 \tr_mean: -103.9 \tr_max: -27.2 \tr_min: -221.2\n",
      " 720 \tr_mean: -100.3 \tr_max: -27.2 \tr_min: -225.1\n",
      " 721 \tr_mean: -100.3 \tr_max: -27.2 \tr_min: -225.1\n",
      " 722 \tr_mean: -96.5 \tr_max: -27.2 \tr_min: -225.1\n",
      " 723 \tr_mean: -96.5 \tr_max: -27.2 \tr_min: -225.1\n",
      " 724 \tr_mean: -93.1 \tr_max: -23.7 \tr_min: -225.1\n",
      " 725 \tr_mean: -89.6 \tr_max: -23.7 \tr_min: -225.1\n",
      " 726 \tr_mean: -89.6 \tr_max: -23.7 \tr_min: -225.1\n",
      " 727 \tr_mean: -87.1 \tr_max: -23.7 \tr_min: -225.1\n",
      " 728 \tr_mean: -87.1 \tr_max: -23.7 \tr_min: -225.1\n",
      " 729 \tr_mean: -85.8 \tr_max: -23.7 \tr_min: -219.3\n",
      " 730 \tr_mean: -85.8 \tr_max: -23.7 \tr_min: -219.3\n",
      " 731 \tr_mean: -84.5 \tr_max: -23.7 \tr_min: -219.3\n",
      " 732 \tr_mean: -84.5 \tr_max: -23.7 \tr_min: -219.3\n",
      " 733 \tr_mean: -89.6 \tr_max: -24.6 \tr_min: -219.3\n",
      " 734 \tr_mean: -94.3 \tr_max: -24.6 \tr_min: -219.3\n",
      " 735 \tr_mean: -94.3 \tr_max: -24.6 \tr_min: -219.3\n",
      " 736 \tr_mean: -96.4 \tr_max: -28.2 \tr_min: -212.4\n",
      " 737 \tr_mean: -96.4 \tr_max: -28.2 \tr_min: -212.4\n",
      " 738 \tr_mean: -101.1 \tr_max: -29.7 \tr_min: -227.3\n",
      " 739 \tr_mean: -101.1 \tr_max: -29.7 \tr_min: -227.3\n",
      " 740 \tr_mean: -101.8 \tr_max: -22.8 \tr_min: -227.3\n",
      " 741 \tr_mean: -101.8 \tr_max: -22.8 \tr_min: -227.3\n",
      " 742 \tr_mean: -98.9 \tr_max: -22.8 \tr_min: -227.3\n",
      " 743 \tr_mean: -97.0 \tr_max: -22.8 \tr_min: -227.3\n",
      " 744 \tr_mean: -97.0 \tr_max: -22.8 \tr_min: -227.3\n",
      " 745 \tr_mean: -97.8 \tr_max: -22.8 \tr_min: -227.3\n",
      " 746 \tr_mean: -97.8 \tr_max: -22.8 \tr_min: -227.3\n",
      " 747 \tr_mean: -97.0 \tr_max: -22.8 \tr_min: -227.0\n",
      " 748 \tr_mean: -97.0 \tr_max: -22.8 \tr_min: -227.0\n",
      " 749 \tr_mean: -100.6 \tr_max: -23.3 \tr_min: -227.0\n",
      " 750 \tr_mean: -97.4 \tr_max: -23.3 \tr_min: -219.3\n",
      " 751 \tr_mean: -97.4 \tr_max: -23.3 \tr_min: -219.3\n",
      " 752 \tr_mean: -95.6 \tr_max: -23.3 \tr_min: -219.3\n",
      " 753 \tr_mean: -95.6 \tr_max: -23.3 \tr_min: -219.3\n",
      " 754 \tr_mean: -94.0 \tr_max: -23.3 \tr_min: -219.3\n",
      " 755 \tr_mean: -94.0 \tr_max: -23.3 \tr_min: -219.3\n",
      " 756 \tr_mean: -91.3 \tr_max: -24.8 \tr_min: -219.3\n",
      " 757 \tr_mean: -91.3 \tr_max: -24.8 \tr_min: -219.3\n",
      " 758 \tr_mean: -87.3 \tr_max: -24.8 \tr_min: -174.3\n",
      " 759 \tr_mean: -90.8 \tr_max: -24.8 \tr_min: -220.5\n",
      " 760 \tr_mean: -90.8 \tr_max: -24.8 \tr_min: -220.5\n",
      " 761 \tr_mean: -94.0 \tr_max: -24.8 \tr_min: -220.5\n",
      " 762 \tr_mean: -94.0 \tr_max: -24.8 \tr_min: -220.5\n",
      " 763 \tr_mean: -94.0 \tr_max: -28.7 \tr_min: -220.5\n",
      " 764 \tr_mean: -94.0 \tr_max: -28.7 \tr_min: -220.5\n",
      " 765 \tr_mean: -95.2 \tr_max: -28.7 \tr_min: -220.5\n",
      " 766 \tr_mean: -95.2 \tr_max: -28.7 \tr_min: -220.5\n",
      " 767 \tr_mean: -94.6 \tr_max: -28.7 \tr_min: -220.5\n",
      " 768 \tr_mean: -93.8 \tr_max: -1.0 \tr_min: -216.5\n",
      " 769 \tr_mean: -93.8 \tr_max: -1.0 \tr_min: -216.5\n",
      " 770 \tr_mean: -91.6 \tr_max: -1.0 \tr_min: -216.5\n",
      " 771 \tr_mean: -91.6 \tr_max: -1.0 \tr_min: -216.5\n",
      " 772 \tr_mean: -90.9 \tr_max: -1.0 \tr_min: -213.0\n",
      " 773 \tr_mean: -90.9 \tr_max: -1.0 \tr_min: -213.0\n",
      " 774 \tr_mean: -87.0 \tr_max: -1.0 \tr_min: -201.3\n",
      " 775 \tr_mean: -89.5 \tr_max: -1.0 \tr_min: -214.4\n",
      " 776 \tr_mean: -89.5 \tr_max: -1.0 \tr_min: -214.4\n",
      " 777 \tr_mean: -91.0 \tr_max: -16.0 \tr_min: -214.4\n",
      " 778 \tr_mean: -91.0 \tr_max: -16.0 \tr_min: -214.4\n",
      " 779 \tr_mean: -92.1 \tr_max: -16.0 \tr_min: -214.4\n",
      " 780 \tr_mean: -92.1 \tr_max: -16.0 \tr_min: -214.4\n",
      " 781 \tr_mean: -92.1 \tr_max: -16.0 \tr_min: -214.4\n",
      " 782 \tr_mean: -92.1 \tr_max: -16.0 \tr_min: -214.4\n",
      " 783 \tr_mean: -97.0 \tr_max: -16.0 \tr_min: -214.4\n",
      " 784 \tr_mean: -96.6 \tr_max: -16.0 \tr_min: -213.1\n",
      " 785 \tr_mean: -96.6 \tr_max: -16.0 \tr_min: -213.1\n",
      " 786 \tr_mean: -96.5 \tr_max: -24.3 \tr_min: -213.1\n",
      " 787 \tr_mean: -96.5 \tr_max: -24.3 \tr_min: -213.1\n",
      " 788 \tr_mean: -93.5 \tr_max: -24.3 \tr_min: -213.1\n",
      " 789 \tr_mean: -93.5 \tr_max: -24.3 \tr_min: -213.1\n",
      " 790 \tr_mean: -93.2 \tr_max: -32.8 \tr_min: -213.1\n",
      " 791 \tr_mean: -93.2 \tr_max: -32.8 \tr_min: -213.1\n",
      " 792 \tr_mean: -91.3 \tr_max: -32.8 \tr_min: -213.1\n",
      " 793 \tr_mean: -92.5 \tr_max: -24.3 \tr_min: -188.5\n",
      " 794 \tr_mean: -92.5 \tr_max: -24.3 \tr_min: -188.5\n",
      " 795 \tr_mean: -90.6 \tr_max: -24.3 \tr_min: -187.8\n",
      " 796 \tr_mean: -90.6 \tr_max: -24.3 \tr_min: -187.8\n",
      " 797 \tr_mean: -91.4 \tr_max: -24.3 \tr_min: -187.8\n",
      " 798 \tr_mean: -91.4 \tr_max: -24.3 \tr_min: -187.8\n",
      " 799 \tr_mean: -92.1 \tr_max: -14.0 \tr_min: -195.2\n",
      " 800 \tr_mean: -93.8 \tr_max: -14.0 \tr_min: -219.2\n",
      " 801 \tr_mean: -93.8 \tr_max: -14.0 \tr_min: -219.2\n",
      " 802 \tr_mean: -94.6 \tr_max: -14.0 \tr_min: -227.5\n",
      " 803 \tr_mean: -94.6 \tr_max: -14.0 \tr_min: -227.5\n",
      " 804 \tr_mean: -93.4 \tr_max: -14.0 \tr_min: -227.5\n",
      " 805 \tr_mean: -93.4 \tr_max: -14.0 \tr_min: -227.5\n",
      " 806 \tr_mean: -95.2 \tr_max: -14.0 \tr_min: -227.5\n",
      " 807 \tr_mean: -95.2 \tr_max: -14.0 \tr_min: -227.5\n",
      " 808 \tr_mean: -96.4 \tr_max: -28.8 \tr_min: -227.5\n",
      " 809 \tr_mean: -96.1 \tr_max: -25.9 \tr_min: -227.5\n",
      " 810 \tr_mean: -96.1 \tr_max: -25.9 \tr_min: -227.5\n",
      " 811 \tr_mean: -95.6 \tr_max: -25.9 \tr_min: -223.2\n",
      " 812 \tr_mean: -95.6 \tr_max: -25.9 \tr_min: -223.2\n",
      " 813 \tr_mean: -98.3 \tr_max: -25.9 \tr_min: -207.4\n",
      " 814 \tr_mean: -98.3 \tr_max: -25.9 \tr_min: -207.4\n",
      " 815 \tr_mean: -96.2 \tr_max: -25.9 \tr_min: -207.4\n",
      " 816 \tr_mean: -96.2 \tr_max: -25.9 \tr_min: -207.4\n",
      " 817 \tr_mean: -94.6 \tr_max: -25.9 \tr_min: -207.4\n",
      " 818 \tr_mean: -92.4 \tr_max: -40.5 \tr_min: -189.5\n",
      " 819 \tr_mean: -92.4 \tr_max: -40.5 \tr_min: -189.5\n",
      " 820 \tr_mean: -90.5 \tr_max: -40.5 \tr_min: -189.0\n",
      " 821 \tr_mean: -90.5 \tr_max: -40.5 \tr_min: -189.0\n",
      " 822 \tr_mean: -91.3 \tr_max: -40.6 \tr_min: -217.7\n",
      " 823 \tr_mean: -91.3 \tr_max: -40.6 \tr_min: -217.7\n",
      " 824 \tr_mean: -92.1 \tr_max: -40.6 \tr_min: -217.7\n",
      " 825 \tr_mean: -94.4 \tr_max: -40.6 \tr_min: -217.7\n",
      " 826 \tr_mean: -94.4 \tr_max: -40.6 \tr_min: -217.7\n",
      " 827 \tr_mean: -98.4 \tr_max: -32.4 \tr_min: -217.7\n",
      " 828 \tr_mean: -98.4 \tr_max: -32.4 \tr_min: -217.7\n",
      " 829 \tr_mean: -99.6 \tr_max: -32.4 \tr_min: -217.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 830 \tr_mean: -99.6 \tr_max: -32.4 \tr_min: -217.8\n",
      " 831 \tr_mean: -101.5 \tr_max: -32.4 \tr_min: -217.8\n",
      " 832 \tr_mean: -101.5 \tr_max: -32.4 \tr_min: -217.8\n",
      " 833 \tr_mean: -104.6 \tr_max: -32.4 \tr_min: -217.8\n",
      " 834 \tr_mean: -107.8 \tr_max: -30.8 \tr_min: -217.8\n",
      " 835 \tr_mean: -107.8 \tr_max: -30.8 \tr_min: -217.8\n",
      " 836 \tr_mean: -106.2 \tr_max: -30.8 \tr_min: -217.8\n",
      " 837 \tr_mean: -106.2 \tr_max: -30.8 \tr_min: -217.8\n",
      " 838 \tr_mean: -109.4 \tr_max: -30.8 \tr_min: -226.2\n",
      " 839 \tr_mean: -109.4 \tr_max: -30.8 \tr_min: -226.2\n",
      " 840 \tr_mean: -109.5 \tr_max: -30.8 \tr_min: -226.2\n",
      " 841 \tr_mean: -109.5 \tr_max: -30.8 \tr_min: -226.2\n",
      " 842 \tr_mean: -110.0 \tr_max: -30.8 \tr_min: -226.2\n",
      " 843 \tr_mean: -110.2 \tr_max: -34.8 \tr_min: -230.6\n",
      " 844 \tr_mean: -110.2 \tr_max: -34.8 \tr_min: -230.6\n",
      " 845 \tr_mean: -115.7 \tr_max: -31.7 \tr_min: -230.6\n",
      " 846 \tr_mean: -115.7 \tr_max: -31.7 \tr_min: -230.6\n",
      " 847 \tr_mean: -117.8 \tr_max: -31.7 \tr_min: -230.6\n",
      " 848 \tr_mean: -117.8 \tr_max: -31.7 \tr_min: -230.6\n",
      " 849 \tr_mean: -117.6 \tr_max: -31.7 \tr_min: -230.6\n",
      " 850 \tr_mean: -115.3 \tr_max: -31.7 \tr_min: -230.6\n",
      " 851 \tr_mean: -115.3 \tr_max: -31.7 \tr_min: -230.6\n",
      " 852 \tr_mean: -119.7 \tr_max: -31.7 \tr_min: -232.5\n",
      " 853 \tr_mean: -119.7 \tr_max: -31.7 \tr_min: -232.5\n",
      " 854 \tr_mean: -117.4 \tr_max: -39.2 \tr_min: -232.5\n",
      " 855 \tr_mean: -117.4 \tr_max: -39.2 \tr_min: -232.5\n",
      " 856 \tr_mean: -113.7 \tr_max: -37.5 \tr_min: -232.5\n",
      " 857 \tr_mean: -113.7 \tr_max: -37.5 \tr_min: -232.5\n",
      " 858 \tr_mean: -111.7 \tr_max: -37.5 \tr_min: -232.5\n",
      " 859 \tr_mean: -115.1 \tr_max: -37.5 \tr_min: -232.5\n",
      " 860 \tr_mean: -115.1 \tr_max: -37.5 \tr_min: -232.5\n",
      " 861 \tr_mean: -111.1 \tr_max: -37.5 \tr_min: -215.1\n",
      " 862 \tr_mean: -111.1 \tr_max: -37.5 \tr_min: -215.1\n",
      " 863 \tr_mean: -110.3 \tr_max: -37.5 \tr_min: -212.2\n",
      " 864 \tr_mean: -110.3 \tr_max: -37.5 \tr_min: -212.2\n",
      " 865 \tr_mean: -113.3 \tr_max: -37.5 \tr_min: -212.2\n",
      " 866 \tr_mean: -113.3 \tr_max: -37.5 \tr_min: -212.2\n",
      " 867 \tr_mean: -113.4 \tr_max: -37.5 \tr_min: -212.2\n",
      " 868 \tr_mean: -114.7 \tr_max: -37.5 \tr_min: -222.2\n",
      " 869 \tr_mean: -114.7 \tr_max: -37.5 \tr_min: -222.2\n",
      " 870 \tr_mean: -112.3 \tr_max: -37.5 \tr_min: -222.2\n",
      " 871 \tr_mean: -112.3 \tr_max: -37.5 \tr_min: -222.2\n",
      " 872 \tr_mean: -111.8 \tr_max: -37.5 \tr_min: -222.2\n",
      " 873 \tr_mean: -111.8 \tr_max: -37.5 \tr_min: -222.2\n",
      " 874 \tr_mean: -110.5 \tr_max: -32.6 \tr_min: -222.2\n",
      " 875 \tr_mean: -110.1 \tr_max: -32.6 \tr_min: -222.2\n",
      " 876 \tr_mean: -110.1 \tr_max: -32.6 \tr_min: -222.2\n",
      " 877 \tr_mean: -105.1 \tr_max: -31.0 \tr_min: -192.0\n",
      " 878 \tr_mean: -105.1 \tr_max: -31.0 \tr_min: -192.0\n",
      " 879 \tr_mean: -101.6 \tr_max: -31.0 \tr_min: -216.4\n",
      " 880 \tr_mean: -101.6 \tr_max: -31.0 \tr_min: -216.4\n",
      " 881 \tr_mean: -97.7 \tr_max: -31.0 \tr_min: -216.4\n",
      " 882 \tr_mean: -97.7 \tr_max: -31.0 \tr_min: -216.4\n",
      " 883 \tr_mean: -92.9 \tr_max: -31.0 \tr_min: -224.1\n",
      " 884 \tr_mean: -89.9 \tr_max: -31.0 \tr_min: -224.1\n",
      " 885 \tr_mean: -89.9 \tr_max: -31.0 \tr_min: -224.1\n",
      " 886 \tr_mean: -88.3 \tr_max: -27.6 \tr_min: -224.1\n",
      " 887 \tr_mean: -88.3 \tr_max: -27.6 \tr_min: -224.1\n",
      " 888 \tr_mean: -85.8 \tr_max: -27.6 \tr_min: -224.1\n",
      " 889 \tr_mean: -85.8 \tr_max: -27.6 \tr_min: -224.1\n",
      " 890 \tr_mean: -79.8 \tr_max: -27.6 \tr_min: -224.1\n",
      " 891 \tr_mean: -79.8 \tr_max: -27.6 \tr_min: -224.1\n",
      " 892 \tr_mean: -73.4 \tr_max: -26.1 \tr_min: -220.1\n",
      " 893 \tr_mean: -67.3 \tr_max: -26.1 \tr_min: -220.1\n",
      " 894 \tr_mean: -67.3 \tr_max: -26.1 \tr_min: -220.1\n",
      " 895 \tr_mean: -60.6 \tr_max: -26.1 \tr_min: -190.3\n",
      " 896 \tr_mean: -60.6 \tr_max: -26.1 \tr_min: -190.3\n",
      " 897 \tr_mean: -62.7 \tr_max: -25.3 \tr_min: -204.1\n",
      " 898 \tr_mean: -62.7 \tr_max: -25.3 \tr_min: -204.1\n",
      " 899 \tr_mean: -66.3 \tr_max: -25.3 \tr_min: -213.5\n",
      " 900 \tr_mean: -66.4 \tr_max: -25.3 \tr_min: -213.5\n",
      " 901 \tr_mean: -66.4 \tr_max: -25.3 \tr_min: -213.5\n",
      " 902 \tr_mean: -72.9 \tr_max: -25.3 \tr_min: -229.2\n",
      " 903 \tr_mean: -72.9 \tr_max: -25.3 \tr_min: -229.2\n",
      " 904 \tr_mean: -78.4 \tr_max: -25.3 \tr_min: -229.2\n",
      " 905 \tr_mean: -78.4 \tr_max: -25.3 \tr_min: -229.2\n",
      " 906 \tr_mean: -82.7 \tr_max: -25.7 \tr_min: -229.2\n",
      " 907 \tr_mean: -82.7 \tr_max: -25.7 \tr_min: -229.2\n",
      " 908 \tr_mean: -80.7 \tr_max: -25.7 \tr_min: -229.2\n",
      " 909 \tr_mean: -86.3 \tr_max: -25.7 \tr_min: -229.2\n",
      " 910 \tr_mean: -86.3 \tr_max: -25.7 \tr_min: -229.2\n",
      " 911 \tr_mean: -89.2 \tr_max: -25.7 \tr_min: -219.8\n",
      " 912 \tr_mean: -89.2 \tr_max: -25.7 \tr_min: -219.8\n",
      " 913 \tr_mean: -95.1 \tr_max: -25.7 \tr_min: -235.9\n",
      " 914 \tr_mean: -95.1 \tr_max: -25.7 \tr_min: -235.9\n",
      " 915 \tr_mean: -96.9 \tr_max: -29.3 \tr_min: -235.9\n",
      " 916 \tr_mean: -96.9 \tr_max: -29.3 \tr_min: -235.9\n",
      " 917 \tr_mean: -105.4 \tr_max: -31.4 \tr_min: -235.9\n",
      " 918 \tr_mean: -109.5 \tr_max: -34.3 \tr_min: -235.9\n",
      " 919 \tr_mean: -109.5 \tr_max: -34.3 \tr_min: -235.9\n",
      " 920 \tr_mean: -111.0 \tr_max: -36.0 \tr_min: -235.9\n",
      " 921 \tr_mean: -111.0 \tr_max: -36.0 \tr_min: -235.9\n",
      " 922 \tr_mean: -111.1 \tr_max: -29.2 \tr_min: -215.1\n",
      " 923 \tr_mean: -111.1 \tr_max: -29.2 \tr_min: -215.1\n",
      " 924 \tr_mean: -109.2 \tr_max: -29.2 \tr_min: -215.1\n",
      " 925 \tr_mean: -106.8 \tr_max: -29.2 \tr_min: -215.1\n",
      " 926 \tr_mean: -106.8 \tr_max: -29.2 \tr_min: -215.1\n",
      " 927 \tr_mean: -99.6 \tr_max: -29.2 \tr_min: -214.4\n",
      " 928 \tr_mean: -99.6 \tr_max: -29.2 \tr_min: -214.4\n",
      " 929 \tr_mean: -98.2 \tr_max: -29.2 \tr_min: -214.4\n",
      " 930 \tr_mean: -98.2 \tr_max: -29.2 \tr_min: -214.4\n",
      " 931 \tr_mean: -97.9 \tr_max: -29.7 \tr_min: -214.4\n",
      " 932 \tr_mean: -97.9 \tr_max: -29.7 \tr_min: -214.4\n",
      " 933 \tr_mean: -99.8 \tr_max: -29.7 \tr_min: -214.4\n",
      " 934 \tr_mean: -103.7 \tr_max: -30.5 \tr_min: -214.0\n",
      " 935 \tr_mean: -103.7 \tr_max: -30.5 \tr_min: -214.0\n",
      " 936 \tr_mean: -112.4 \tr_max: -30.5 \tr_min: -229.8\n",
      " 937 \tr_mean: -112.4 \tr_max: -30.5 \tr_min: -229.8\n",
      " 938 \tr_mean: -112.5 \tr_max: -29.9 \tr_min: -229.8\n",
      " 939 \tr_mean: -112.5 \tr_max: -29.9 \tr_min: -229.8\n",
      " 940 \tr_mean: -103.7 \tr_max: -25.8 \tr_min: -229.8\n",
      " 941 \tr_mean: -103.7 \tr_max: -25.8 \tr_min: -229.8\n",
      " 942 \tr_mean: -99.2 \tr_max: -25.8 \tr_min: -229.8\n",
      " 943 \tr_mean: -91.3 \tr_max: -25.8 \tr_min: -229.8\n",
      " 944 \tr_mean: -91.3 \tr_max: -25.8 \tr_min: -229.8\n",
      " 945 \tr_mean: -88.5 \tr_max: -25.8 \tr_min: -221.5\n",
      " 946 \tr_mean: -88.5 \tr_max: -25.8 \tr_min: -221.5\n",
      " 947 \tr_mean: -84.5 \tr_max: -25.8 \tr_min: -221.5\n",
      " 948 \tr_mean: -84.5 \tr_max: -25.8 \tr_min: -221.5\n",
      " 949 \tr_mean: -86.3 \tr_max: -23.3 \tr_min: -221.5\n",
      " 950 \tr_mean: -85.9 \tr_max: -23.3 \tr_min: -221.5\n",
      " 951 \tr_mean: -85.9 \tr_max: -23.3 \tr_min: -221.5\n",
      " 952 \tr_mean: -86.3 \tr_max: -23.3 \tr_min: -221.5\n",
      " 953 \tr_mean: -86.3 \tr_max: -23.3 \tr_min: -221.5\n",
      " 954 \tr_mean: -84.2 \tr_max: -23.3 \tr_min: -215.4\n",
      " 955 \tr_mean: -84.2 \tr_max: -23.3 \tr_min: -215.4\n",
      " 956 \tr_mean: -83.1 \tr_max: -23.3 \tr_min: -215.4\n",
      " 957 \tr_mean: -83.1 \tr_max: -23.3 \tr_min: -215.4\n",
      " 958 \tr_mean: -83.4 \tr_max: -24.0 \tr_min: -215.4\n",
      " 959 \tr_mean: -79.2 \tr_max: -24.0 \tr_min: -215.4\n",
      " 960 \tr_mean: -79.2 \tr_max: -24.0 \tr_min: -215.4\n",
      " 961 \tr_mean: -79.7 \tr_max: -24.0 \tr_min: -169.0\n",
      " 962 \tr_mean: -79.7 \tr_max: -24.0 \tr_min: -169.0\n",
      " 963 \tr_mean: -82.1 \tr_max: -24.0 \tr_min: -197.4\n",
      " 964 \tr_mean: -82.1 \tr_max: -24.0 \tr_min: -197.4\n",
      " 965 \tr_mean: -85.4 \tr_max: -24.0 \tr_min: -211.6\n",
      " 966 \tr_mean: -85.4 \tr_max: -24.0 \tr_min: -211.6\n",
      " 967 \tr_mean: -88.9 \tr_max: -28.1 \tr_min: -211.6\n",
      " 968 \tr_mean: -88.0 \tr_max: -28.1 \tr_min: -211.6\n",
      " 969 \tr_mean: -88.0 \tr_max: -28.1 \tr_min: -211.6\n",
      " 970 \tr_mean: -91.6 \tr_max: -26.2 \tr_min: -224.7\n",
      " 971 \tr_mean: -91.6 \tr_max: -26.2 \tr_min: -224.7\n",
      " 972 \tr_mean: -87.5 \tr_max: -26.2 \tr_min: -224.7\n",
      " 973 \tr_mean: -87.5 \tr_max: -26.2 \tr_min: -224.7\n",
      " 974 \tr_mean: -81.7 \tr_max: -26.2 \tr_min: -224.7\n",
      " 975 \tr_mean: -82.1 \tr_max: -26.2 \tr_min: -224.7\n",
      " 976 \tr_mean: -82.1 \tr_max: -26.2 \tr_min: -224.7\n",
      " 977 \tr_mean: -87.4 \tr_max: -22.6 \tr_min: -224.7\n",
      " 978 \tr_mean: -87.4 \tr_max: -22.6 \tr_min: -224.7\n",
      " 979 \tr_mean: -82.5 \tr_max: -22.6 \tr_min: -218.5\n",
      " 980 \tr_mean: -82.5 \tr_max: -22.6 \tr_min: -218.5\n",
      " 981 \tr_mean: -86.6 \tr_max: -22.6 \tr_min: -223.4\n",
      " 982 \tr_mean: -86.6 \tr_max: -22.6 \tr_min: -223.4\n",
      " 983 \tr_mean: -97.1 \tr_max: -22.6 \tr_min: -223.4\n",
      " 984 \tr_mean: -101.6 \tr_max: -22.6 \tr_min: -224.7\n",
      " 985 \tr_mean: -101.6 \tr_max: -22.6 \tr_min: -224.7\n",
      " 986 \tr_mean: -103.8 \tr_max: -23.7 \tr_min: -224.7\n",
      " 987 \tr_mean: -103.8 \tr_max: -23.7 \tr_min: -224.7\n",
      " 988 \tr_mean: -107.3 \tr_max: -23.7 \tr_min: -224.7\n",
      " 989 \tr_mean: -107.3 \tr_max: -23.7 \tr_min: -224.7\n",
      " 990 \tr_mean: -111.1 \tr_max: -34.2 \tr_min: -227.4\n",
      " 991 \tr_mean: -111.1 \tr_max: -34.2 \tr_min: -227.4\n",
      " 992 \tr_mean: -111.1 \tr_max: -34.2 \tr_min: -227.4\n",
      " 993 \tr_mean: -110.2 \tr_max: -34.2 \tr_min: -227.4\n",
      " 994 \tr_mean: -110.2 \tr_max: -34.2 \tr_min: -227.4\n",
      " 995 \tr_mean: -114.1 \tr_max: -34.2 \tr_min: -227.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 996 \tr_mean: -114.1 \tr_max: -34.2 \tr_min: -227.4\n",
      " 997 \tr_mean: -116.4 \tr_max: -38.2 \tr_min: -228.8\n",
      " 998 \tr_mean: -116.4 \tr_max: -38.2 \tr_min: -228.8\n",
      " 999 \tr_mean: -113.4 \tr_max: -38.2 \tr_min: -229.5\n",
      "1000 \tr_mean: -112.1 \tr_max: -41.1 \tr_min: -229.5\n",
      "1001 \tr_mean: -112.1 \tr_max: -41.1 \tr_min: -229.5\n",
      "1002 \tr_mean: -107.5 \tr_max: -40.3 \tr_min: -229.5\n",
      "1003 \tr_mean: -107.5 \tr_max: -40.3 \tr_min: -229.5\n",
      "1004 \tr_mean: -98.0 \tr_max: -29.2 \tr_min: -229.5\n",
      "1005 \tr_mean: -98.0 \tr_max: -29.2 \tr_min: -229.5\n",
      "1006 \tr_mean: -92.0 \tr_max: -22.8 \tr_min: -229.5\n",
      "1007 \tr_mean: -92.0 \tr_max: -22.8 \tr_min: -229.5\n",
      "1008 \tr_mean: -86.4 \tr_max: -22.8 \tr_min: -206.8\n",
      "1009 \tr_mean: -78.3 \tr_max: -22.8 \tr_min: -206.8\n",
      "1010 \tr_mean: -78.3 \tr_max: -22.8 \tr_min: -206.8\n",
      "1011 \tr_mean: -77.5 \tr_max: -22.8 \tr_min: -202.1\n",
      "1012 \tr_mean: -77.5 \tr_max: -22.8 \tr_min: -202.1\n",
      "1013 \tr_mean: -77.3 \tr_max: -22.8 \tr_min: -202.1\n",
      "1014 \tr_mean: -77.3 \tr_max: -22.8 \tr_min: -202.1\n",
      "1015 \tr_mean: -75.8 \tr_max: -26.6 \tr_min: -202.1\n",
      "1016 \tr_mean: -75.8 \tr_max: -26.6 \tr_min: -202.1\n",
      "1017 \tr_mean: -74.5 \tr_max: -26.6 \tr_min: -202.1\n",
      "1018 \tr_mean: -75.8 \tr_max: -26.6 \tr_min: -202.1\n",
      "1019 \tr_mean: -75.8 \tr_max: -26.6 \tr_min: -202.1\n",
      "1020 \tr_mean: -76.1 \tr_max: -26.6 \tr_min: -171.1\n",
      "1021 \tr_mean: -76.1 \tr_max: -26.6 \tr_min: -171.1\n",
      "1022 \tr_mean: -73.3 \tr_max: -21.7 \tr_min: -171.1\n",
      "1023 \tr_mean: -73.3 \tr_max: -21.7 \tr_min: -171.1\n",
      "1024 \tr_mean: -74.4 \tr_max: -21.7 \tr_min: -171.1\n",
      "1025 \tr_mean: -77.4 \tr_max: -21.7 \tr_min: -177.6\n",
      "1026 \tr_mean: -77.4 \tr_max: -21.7 \tr_min: -177.6\n",
      "1027 \tr_mean: -77.6 \tr_max: -21.7 \tr_min: -177.6\n",
      "1028 \tr_mean: -77.6 \tr_max: -21.7 \tr_min: -177.6\n",
      "1029 \tr_mean: -76.5 \tr_max: -21.7 \tr_min: -177.6\n",
      "1030 \tr_mean: -76.5 \tr_max: -21.7 \tr_min: -177.6\n",
      "1031 \tr_mean: -81.2 \tr_max: -21.8 \tr_min: -177.6\n",
      "1032 \tr_mean: -81.2 \tr_max: -21.8 \tr_min: -177.6\n",
      "1033 \tr_mean: -82.2 \tr_max: -21.8 \tr_min: -177.6\n",
      "1034 \tr_mean: -83.2 \tr_max: -21.8 \tr_min: -226.9\n",
      "1035 \tr_mean: -83.2 \tr_max: -21.8 \tr_min: -226.9\n",
      "1036 \tr_mean: -83.2 \tr_max: -25.9 \tr_min: -226.9\n",
      "1037 \tr_mean: -83.2 \tr_max: -25.9 \tr_min: -226.9\n",
      "1038 \tr_mean: -82.6 \tr_max: -25.9 \tr_min: -226.9\n",
      "1039 \tr_mean: -82.6 \tr_max: -25.9 \tr_min: -226.9\n",
      "1040 \tr_mean: -81.5 \tr_max: -25.9 \tr_min: -226.9\n",
      "1041 \tr_mean: -81.5 \tr_max: -25.9 \tr_min: -226.9\n",
      "1042 \tr_mean: -83.7 \tr_max: -25.9 \tr_min: -226.9\n",
      "1043 \tr_mean: -86.4 \tr_max: -25.9 \tr_min: -222.6\n",
      "1044 \tr_mean: -86.4 \tr_max: -25.9 \tr_min: -222.6\n",
      "1045 \tr_mean: -86.6 \tr_max: -27.7 \tr_min: -219.6\n",
      "1046 \tr_mean: -86.6 \tr_max: -27.7 \tr_min: -219.6\n",
      "1047 \tr_mean: -87.2 \tr_max: -27.7 \tr_min: -219.6\n",
      "1048 \tr_mean: -87.2 \tr_max: -27.7 \tr_min: -219.6\n",
      "1049 \tr_mean: -92.9 \tr_max: -27.7 \tr_min: -219.6\n",
      "1050 \tr_mean: -98.5 \tr_max: -27.7 \tr_min: -216.1\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.dqn import dqn\n",
    "import ray\n",
    "\n",
    "all_rewards = []\n",
    "\n",
    "\n",
    "dqn_config = dqn.DEFAULT_CONFIG.copy()\n",
    "dqn_config.update({\"num_gpus\": 1,\"num_workers\":20,\n",
    "                    \"explore\": True,\n",
    "                    \"framework\": \"tf\",\n",
    "                    \"horizon\": 100,\n",
    "                    'lr': .00002,\n",
    "                    'train_batch_size': 64,\n",
    "                    'double_q': True,\n",
    "                    'dueling': True,\n",
    "                    'num_atoms': 51,\n",
    "                    'target_network_update_freq': 2000,\n",
    "                    'rollout_fragment_length': 8,\n",
    "                    'replay_buffer_config': {'_enable_replay_buffer_api': True,\n",
    "                      'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "                      'capacity': 50000,\n",
    "                      'prioritized_replay_alpha': 0.6,\n",
    "                      'prioritized_replay_beta': 0.4,\n",
    "                      'prioritized_replay_eps': 1e-06,\n",
    "                      'replay_sequence_length': 1},\n",
    "                    \"gamma\":0.9,\n",
    "                    'hiddens': [512],\n",
    "                    \"model\": {\n",
    "                        \"fcnet_hiddens\": [512],\n",
    "                        \"fcnet_activation\": \"relu\",\n",
    "                    },\n",
    "                    'evaluation_config': {'evaluation_parallel_to_training': True,\n",
    "                                        'evaluation_num_workers': 2,\n",
    "                                         'evaluation_interval': 1},\n",
    "                    }) \n",
    "rewards = []\n",
    "trainer = DQNTrainer_Offline(config=dqn_config, env=\"CybORG\")\n",
    "\n",
    "for i in range(int(200000)):\n",
    "    results_dict=trainer.train()\n",
    "    print_results(results_dict)\n",
    "    rewards.append(results_dict[\"episode_reward_mean\"])\n",
    "all_rewards.append(rewards)\n",
    "np.save(n+'.npy',rewards)\n",
    "trainer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,12))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(al[0], label=\"GA Data\")\n",
    "ax1.plot(al[1], label=\"PPO Data\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Offline DQN')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(50000)):\n",
    "    results_dict=trainer.train()\n",
    "    print_results(results_dict)\n",
    "    rewards.append(results_dict[\"episode_reward_mean\"])\n",
    "all_rewards.append(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,12))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(rewards[3], label=\"\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Store Size (B_lineAgent)')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['ls', os.path.join(ray._private.utils.get_user_temp_dir(), \"8_data_s\")], stdout=subprocess.PIPE)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"8_data_s_smallish\"+'.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"/8_data_s_smallish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['ls',\"/8_data_s_smallish\"], stdout=subprocess.PIPE)\n",
    "len(str(result.stdout)[2:].split('\\\\n')[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['ls',\"/85_data_a\"], stdout=subprocess.PIPE)\n",
    "for i, s in enumerate(str(result.stdout)[2:].split('\\\\n')[0:-1]):\n",
    "    if i % 2 == 0:\n",
    "        os.remove(\"/85_data_a/\" + s)\n",
    "        #shutil.copyfile(os.path.join(ay._private.utils.get_user_temp_dir(), \"82_data_s_a\",s), os.path.join(\"8_data_s\",s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in str(result.stdout)[2:].split('\\\\n'):\n",
    "    os.remove(os.path.join(\"/85_data_a\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(result.stdout)[2:].split('\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "removed = 0\n",
    "result = subprocess.run(['ls', \"/ppo\"], stdout=subprocess.PIPE)\n",
    "for j, name in enumerate(str(result.stdout)[2:].split('\\\\n')[0:-1]):\n",
    "    f = open(os.path.join(\"/ppo\", name))\n",
    "    try:\n",
    "        obj = json.load(f)\n",
    "        with open('/ppo2/'+name, 'w') as fp:\n",
    "            json.dump(obj[\"value\"], fp)\n",
    "    except ValueError as err:\n",
    "        #os.remove(os.path.join(\"/ppo\", name)) \n",
    "        removed += 1\n",
    "print('Removed ' + str(removed) + ' files, of ' + str(j) + 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/ppo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
